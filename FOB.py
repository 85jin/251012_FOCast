# FOB.py (v0.3) â€” FOCast web app
# V5 schema + rate-based alerts + dependent filters + chart axis toggle + XLSX engine fallback

import io
from datetime import datetime, timedelta, date

import numpy as np
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components

# ì‹œê°í™”(ì¶• ì „í™˜/ë ˆì´ì–´ë§)ë¥¼ ìœ„í•´ Altair ì‚¬ìš©
import altair as alt

# -----------------------------
# ì „ì—­ ì„¤ì • ë° ìƒìˆ˜
# -----------------------------
st.set_page_config(page_title="FOCast - ì´ë¬¼ ë¶„ì„Â·ì•Œë¦¼", layout="wide", initial_sidebar_state="expanded")
APP_TITLE = "FOCast â€“ ì´ë¬¼ ë¶„ì„Â·ì•Œë¦¼ ì›¹ì•±"
SECRET_CODE = "cj123456"  # ì£¼ê¸°ì  ë³€ê²½ ì˜ˆì •

# V5 ìŠ¤í‚¤ë§ˆ (stage ì œê±°, material_type ì¶”ê°€)
REQUIRED_COLUMNS = [
    "dt","plant","line",
    "material_type",          # NEW in V5
    "material_code","material_name",
    "supplier_code","supplier_name",
    "contam_type","color_tags",
    "count","unit","lot_no","severity",
    "photo_url","notes",
    "origin","imported",
    "selection_amount_kg",
    "ì´ë¬¼ìˆ˜ì¤€","ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€","ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"
]

DEFAULT_RECENT_DAYS = 7
DEFAULT_BASELINE_DAYS = 180
SURGE_Z_THRESHOLD = 3.0  # z >= 3 ìƒìŠ¹, z <= -3 í•˜ë½

# -----------------------------
# ì¸ì¦
# -----------------------------
def auth_gate():
    st.markdown("### ğŸ” ë³´ì•ˆì½”ë“œ ì…ë ¥")
    with st.form("auth_form", clear_on_submit=False):
        code = st.text_input("ë³´ì•ˆì½”ë“œ", type="password", help="ì ‘ì† ë³´ì•ˆì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        ok = st.form_submit_button("ì ‘ì†")
        if ok:
            if code == SECRET_CODE:
                st.session_state["_authed"] = True
                st.success("ì ‘ì† í—ˆìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.session_state["_authed"] = False
                st.error("ë³´ì•ˆì½”ë“œê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

if "_authed" not in st.session_state:
    st.session_state["_authed"] = False

st.title(APP_TITLE)

if not st.session_state["_authed"]:
    auth_gate()
    st.stop()

# -----------------------------
# ìœ í‹¸ & ì „ì²˜ë¦¬
# -----------------------------
@st.cache_data(show_spinner=False)
def load_file(uploaded_file, sheet_name: str | None = None) -> pd.DataFrame:
    """CSV/Excel íŒŒì¼ ë¡œë“œ (ì—‘ì…€ì€ ê¸°ë³¸ì ìœ¼ë¡œ 'ì²« ë²ˆì§¸ ì‹œíŠ¸' ë˜ëŠ” 'Incidents' ì‹œíŠ¸ ì„ íƒ)"""
    name = uploaded_file.name.lower()

    # CSV ì²˜ë¦¬: ì¸ì½”ë”© ìë™ í´ë°±
    if name.endswith(".csv"):
        try:
            return pd.read_csv(uploaded_file)  # ê¸°ë³¸ UTF-8
        except UnicodeDecodeError:
            uploaded_file.seek(0)
            return pd.read_csv(uploaded_file, encoding="cp949")

    # Excel ì²˜ë¦¬
    if name.endswith((".xlsx", ".xls")):
        import openpyxl  # ensure installed
        # 1) ì‚¬ìš©ìê°€ ì‹œíŠ¸ëª…ì„ ì§€ì •í•œ ê²½ìš°
        if sheet_name and str(sheet_name).strip():
            return pd.read_excel(uploaded_file, sheet_name=str(sheet_name).strip(), engine="openpyxl")

        # 2) ë¯¸ì§€ì • ì‹œ â†’ ì²« ì‹œíŠ¸ ë˜ëŠ” 'Incidents' ìš°ì„  ì„ íƒ
        xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
        preferred = [s for s in xls.sheet_names if s.lower() in ("incidents", "data", "sheet1")]
        pick = preferred[0] if preferred else xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=pick)
        # ì„ íƒëœ ì‹œíŠ¸ëª…ì„ í™”ë©´ì— í‘œì‹œ(ë””ë²„ê¹…/ê°€ì´ë“œìš©)
        st.caption(f"ì—‘ì…€ ì‹œíŠ¸ ìë™ ì„ íƒ: **{pick}** (íŒŒì¼ ë‚´ ì‹œíŠ¸: {', '.join(xls.sheet_names)})")
        return df

    raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” Excel(.xlsx/.xls)ë§Œ ì—…ë¡œë“œí•˜ì„¸ìš”.")

def ensure_columns(df: pd.DataFrame) -> pd.DataFrame:
    """í•„ìˆ˜ ì»¬ëŸ¼/íƒ€ì… ë³´ì • (V5)"""
    for col in REQUIRED_COLUMNS:
        if col not in df.columns:
            df[col] = np.nan

    # ë‚ ì§œ íŒŒì‹±: V5ëŠ” ë‚ ì§œê¹Œì§€ë§Œ ì¡´ì¬
    try:
        df["dt"] = pd.to_datetime(df["dt"]).dt.date
    except Exception:
        df["dt"] = pd.to_datetime(df["dt"], errors="coerce").dt.date

    # ìˆ«ìí˜•
    for c in ["count", "selection_amount_kg", "ì´ë¬¼ìˆ˜ì¤€", "ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€", "ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    df["count"] = df["count"].fillna(0).astype(int)
    df["selection_amount_kg"] = df["selection_amount_kg"].fillna(0).astype(int)
    for c in ["ì´ë¬¼ìˆ˜ì¤€","ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€","ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"]:
        df[c] = df[c].fillna(0.0).astype(float)

    # ë¬¸ìì—´í˜•
    str_cols = [
        "plant","line","material_type","material_code","material_name",
        "supplier_code","supplier_name","contam_type","color_tags",
        "unit","lot_no","severity","photo_url","notes","origin","imported"
    ]
    for c in str_cols:
        df[c] = df[c].fillna("").astype(str)

    return df

def split_tags(s: str):
    if not isinstance(s, str):
        return []
    return [t.strip() for t in s.split(";") if t.strip()]

def tag_filter_mask(series_tags: pd.Series, selected_tags, mode="ANY"):
    if not selected_tags:
        return pd.Series([True]*len(series_tags), index=series_tags.index)
    row_tags = series_tags.apply(split_tags)
    if mode == "ALL":
        mask = row_tags.apply(lambda lst: all(t in lst for t in selected_tags))
    else:
        mask = row_tags.apply(lambda lst: any(t in lst for t in selected_tags))
    return mask

def flatten_index(idx):
    if hasattr(idx, "names") and isinstance(idx, pd.MultiIndex):
        return [" | ".join(map(str, tup)) for tup in idx.to_list()]
    return [str(x) for x in idx]

# -----------------------------
# ë¶„ì„ í•¨ìˆ˜ (V5: rate ê¸°ë°˜)
# -----------------------------
def detect_novel_types(df: pd.DataFrame,
                       key_cols=("supplier_code","material_code"),
                       type_col="contam_type",
                       time_col="dt") -> pd.DataFrame:
    f = df[[*key_cols, type_col, time_col]].copy()
    f = f.sort_values(time_col)
    seen, flags = {}, []
    for _, row in f.iterrows():
        key = tuple(row[c] for c in key_cols)
        t = row[type_col]
        if key not in seen:
            seen[key] = set()
        novel = t not in seen[key]
        flags.append(novel)
        seen[key].add(t)
    f["is_novel_type"] = flags
    return f

def rate_change_flag_v5(df: pd.DataFrame,
                        key_cols=("supplier_code","material_code","contam_type"),
                        count_col="count",
                        exposure_col="selection_amount_kg",
                        time_col="dt",
                        recent_days=DEFAULT_RECENT_DAYS,
                        baseline_days=DEFAULT_BASELINE_DAYS) -> pd.DataFrame:
    """ì´ë¬¼ìˆ˜ì¤€(=count/exposure) ê¸°ë°˜ ê¸‰ì¦/í•˜ë½ íƒì§€.
       z = (r_recent - r_base) / sqrt(r_base / recent_exposure)
       (Poisson with exposure ê·¼ì‚¬, small-sample ì•ˆì •í™” í¬í•¨)
    """
    g = df[[*key_cols, count_col, exposure_col, time_col]].copy()
    g["date"] = g[time_col]
    if g["date"].isna().all():
        return pd.DataFrame()

    today = max([d for d in g["date"] if pd.notna(d)], default=None)
    if pd.isna(today) or today is None:
        return pd.DataFrame()

    recent_start = today - timedelta(days=recent_days-1)
    base_end = recent_start - timedelta(days=1)
    base_start = base_end - timedelta(days=baseline_days-1)

    recent = g[(g["date"]>=recent_start) & (g["date"]<=today)]
    base   = g[(g["date"]>=base_start) & (g["date"]<=base_end)]

    if recent.empty and base.empty:
        return pd.DataFrame()

    # ì§‘ê³„: ë¶„ì/ë¶„ëª¨ ë”°ë¡œ í•©ì‚°
    r = recent.groupby(list(key_cols))[[count_col, exposure_col]].sum().rename(columns={
        count_col: "x_cnt", exposure_col: "x_exp"
    }).reset_index()
    b = base.groupby(list(key_cols))[[count_col, exposure_col]].sum().rename(columns={
        count_col: "b_cnt", exposure_col: "b_exp"
    }).reset_index()

    merged = pd.merge(r, b, on=list(key_cols), how="outer").fillna(0)

    # rate ê³„ì‚°
    merged["x_rate"] = np.where(merged["x_exp"]>0, merged["x_cnt"] / merged["x_exp"], 0.0)
    merged["b_rate"] = np.where(merged["b_exp"]>0, merged["b_cnt"] / merged["b_exp"], 0.0)

    # ìµœê·¼ ê¸°ëŒ€ rate = b_rate (ê¸°ì¤€ì„ )
    merged["expected_recent_rate"] = merged["b_rate"]

    # z-score (ì•ˆì •í™”: base_rate ìµœì†Œê°’ ë°”ë‹¥ì¹˜)
    eps = 1e-9
    denom = np.sqrt((merged["b_rate"] + eps) / (merged["x_exp"] + eps))
    merged["z"] = (merged["x_rate"] - merged["b_rate"]) / denom.replace(0, np.nan)
    merged["z"] = merged["z"].replace([np.inf, -np.inf], 0).fillna(0)

    merged["flag"] = np.select(
        [merged["z"] >= SURGE_Z_THRESHOLD, merged["z"] <= -SURGE_Z_THRESHOLD],
        ["ìƒìŠ¹","í•˜ë½"], default="ì •ìƒ"
    )

    # ì°¸ê³ ìš© ì»¬ëŸ¼(ê¸°ì¡´í‘œí˜„ ìœ ì§€)
    merged["x"] = merged["x_cnt"]
    merged["base_count"] = merged["b_cnt"]
    merged["expected_recent"] = merged["expected_recent_rate"] * merged["x_exp"]

    # ì •ë ¬
    merged = merged.sort_values("z", ascending=False)
    return merged

# -----------------------------
# ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ (êµì²´)
# -----------------------------
with st.sidebar:
    st.header("â‘  ë°ì´í„° ì—…ë¡œë“œ")
    uploaded = st.file_uploader("ì—‘ì…€/CSV ì—…ë¡œë“œ", type=["csv","xlsx","xls"])

    # ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•´ ê°•ì œ ì§€ì •í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ì…ë ¥(ì˜µì…˜)
    sheet_name_input = st.text_input("ì—‘ì…€ ì‹œíŠ¸ëª…(ì˜µì…˜)", value="")

    # ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—‘ì…€ì´ë¼ë©´: ì‹œíŠ¸ ëª©ë¡ ì•ˆë‚´ + ì„ íƒ ë°•ìŠ¤ ì œê³µ
    sheet_choice = None
    if uploaded and uploaded.name.lower().endswith((".xlsx", ".xls")):
        try:
            import openpyxl  # ensure installed
            # ì—…ë¡œë” ìŠ¤íŠ¸ë¦¼ì„ í•œë²ˆ ì½ìœ¼ë©´ í¬ì¸í„°ê°€ ì´ë™í•˜ë¯€ë¡œ, ì‚¬ìš© í›„ ë°˜ë“œì‹œ seek(0) ë³µêµ¬
            xls = pd.ExcelFile(uploaded, engine="openpyxl")
            # ëª©ë¡ ì•ˆë‚´
            st.caption("ì´ íŒŒì¼ì˜ ì‹œíŠ¸: " + ", ".join(xls.sheet_names))

            # ì¶”ì²œ ê¸°ë³¸ ì‹œíŠ¸(ìˆìœ¼ë©´ incidents/data/sheet1 â†’ ì—†ìœ¼ë©´ ì²« ì‹œíŠ¸)
            preferred = [s for s in xls.sheet_names if s.lower() in ("incidents", "data", "sheet1")]
            default_sheet = preferred[0] if preferred else xls.sheet_names[0]
            default_idx = xls.sheet_names.index(default_sheet)

            # ì„ íƒ UI
            sheet_choice = st.selectbox("ì‹œíŠ¸ ì„ íƒ(ìë™ ê°ì§€)", options=xls.sheet_names, index=default_idx)

        except Exception as e:
            st.warning(f"ì‹œíŠ¸ ëª©ë¡ì„ ì½ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        finally:
            # ì´í›„ ì‹¤ì œ ë¡œë”©ì„ ìœ„í•´ íŒŒì¼ í¬ì¸í„° ë³µêµ¬
            try:
                uploaded.seek(0)
            except Exception:
                pass

    st.header("â‘¡ íƒœê·¸ ë§¤ì¹­")
    tag_mode = st.radio("íƒœê·¸ ëª¨ë“œ", ["ANY(í•˜ë‚˜ë¼ë„ ì¼ì¹˜)","ALL(ëª¨ë‘ í¬í•¨)"], index=0)
    st.caption("ğŸ’¡ ì—…ë¡œë“œ í›„ ìƒë‹¨ íƒ­ì—ì„œ í”¼ë²—/ê²½ë³´/ì•¡ì…˜/ë‚´ë³´ë‚´ê¸°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

if uploaded is None:
    st.info("ì™¼ìª½ì—ì„œ CSV ë˜ëŠ” ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (V5 ìŠ¤í‚¤ë§ˆ ê¶Œì¥)")
    st.stop()

# í…ìŠ¤íŠ¸ ì…ë ¥ì´ ìš°ì„ , ì—†ìœ¼ë©´ ì„ íƒë°•ìŠ¤ ê°’ ì‚¬ìš©
chosen_sheet = sheet_name_input.strip() or sheet_choice

try:
    df_raw = load_file(uploaded, sheet_name=chosen_sheet if chosen_sheet else None)
except Exception as e:
    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
    st.stop()


df = ensure_columns(df_raw)

min_dt = pd.to_datetime(df["dt"]).min()
max_dt = pd.to_datetime(df["dt"]).max()

# -----------------------------
# ìƒë‹¨ KPI
# -----------------------------
k1,k2,k3,k4 = st.columns(4)
with k1:
    st.metric("ì´ ê±´ìˆ˜", f"{len(df):,}")
with k2:
    st.metric("ê³ ìœ  ì›ë£Œì½”ë“œ", df["material_code"].nunique())
with k3:
    st.metric("ê³µê¸‰ì‚¬ ìˆ˜", df["supplier_code"].nunique())
with k4:
    st.metric("ê¸°ê°„ ë²”ìœ„", f"{min_dt} ~ {max_dt}" if pd.notna(min_dt) else "-")

# íƒ­ ìƒíƒœ
st.session_state.setdefault("pivot_df", None)
st.session_state.setdefault("alerts_novel", None)
st.session_state.setdefault("alerts_surge", None)
st.session_state.setdefault("filtered_df", None)

# -----------------------------
# íƒ­ êµ¬ì„±
# -----------------------------
tab1, tab2, tab3, tab4 = st.tabs([
    "â‘  í”¼ë²—/í•„í„° ê²€ìƒ‰", "â‘¡ ê²½ë³´ ë³´ë“œ", "â‘¢ ì•¡ì…˜ í…œí”Œë¦¿", "â‘£ ë‚´ë³´ë‚´ê¸°"
])

# -----------------------------
# â‘  í”¼ë²—/í•„í„° ê²€ìƒ‰
# -----------------------------
with tab1:
    st.subheader("í”¼ë²—/í•„í„° ê²€ìƒ‰")

    # ---- í•„í„° (4ê°œì”© ë°°ì¹˜) ----
    today_d = date.today()
    default_start = today_d - timedelta(days=365)
    default_end = today_d

    # material_typeâ†’ material_name/code ì˜ì¡´ì„ ìœ„í•œ ë§µ
    map_type_to_materials = (
        df.groupby("material_type")[["material_code","material_name"]]
          .apply(lambda g: g.drop_duplicates().to_dict("records"))
          .to_dict()
    )

    # 1í–‰
    c1,c2,c3,c4 = st.columns(4)
    with c1:
        plants = st.multiselect("ê³µì¥(plant)", sorted([p for p in df["plant"].unique() if p!=""]))
    with c2:
        lines = st.multiselect("ë¼ì¸(line)", sorted([p for p in df["line"].unique() if p!=""]))
    with c3:
        suppliers = st.multiselect("ê³µê¸‰ì‚¬ ì½”ë“œ(supplier_code)", sorted([p for p in df["supplier_code"].unique() if p!=""]), key="supplier_select")
    with c4:
        supplier_names = st.multiselect("ê³µê¸‰ì‚¬ëª…(supplier_name)", sorted([p for p in df["supplier_name"].unique() if p!=""]))

    # 2í–‰
    c5,c6,c7,c8 = st.columns(4)
    with c5:
        mat_types = st.multiselect("ì›ë£ŒëŒ€ë¶„ë¥˜(material_type)", sorted([p for p in df["material_type"].unique() if p!=""]), key="mat_type_select")
    with c6:
        # material_type & supplier êµì§‘í•©ìœ¼ë¡œ material í›„ë³´ ì œí•œ
        if mat_types:
            subset = df[df["material_type"].isin(mat_types)]
        else:
            subset = df
        if suppliers or supplier_names:
            subset = subset[
                subset["supplier_code"].isin(suppliers) if suppliers else subset.index.isin(subset.index)
            ]
            if supplier_names:
                subset = subset[subset["supplier_name"].isin(supplier_names)]
        mat_name_opts = sorted(subset["material_name"].dropna().unique())
        material_names = st.multiselect("ì›ë£Œëª…(material_name)", mat_name_opts, key="material_name_select")
    with c7:
        # material_nameì„ ì¬ì°¨ ë°˜ì˜í•´ code í›„ë³´ ì œí•œ
        subset2 = subset[subset["material_name"].isin(material_names)] if material_names else subset
        mat_code_opts = sorted(subset2["material_code"].dropna().unique())
        materials = st.multiselect("ì›ë£Œì½”ë“œ(material_code)", mat_code_opts, key="material_code_select")
    with c8:
        fo_types = st.multiselect("ì´ë¬¼ ìœ í˜•(contam_type)", sorted([p for p in df["contam_type"].unique() if p!=""]))

    # 3í–‰
    c9,c10,c11,c12 = st.columns(4)
    with c9:
        severities = st.multiselect("ì¤‘ëŒ€/ì¼ë°˜(severity)", ["ì¤‘ëŒ€","ì¼ë°˜"])
    with c10:
        origins = st.multiselect("ì›ì‚°ì§€(origin)", sorted([p for p in df["origin"].unique() if p!=""]))
    with c11:
        imported = st.multiselect("ìˆ˜ì…ì—¬ë¶€(imported)", sorted([p for p in df["imported"].unique() if p!=""]))
    with c12:
        unique_tags = sorted({t for row in df["color_tags"] for t in split_tags(row)})
        tags = st.multiselect("íƒœê·¸(color_tags)", unique_tags)

    # 4í–‰ (ê¸°ê°„)
    c13,c14,c15,c16 = st.columns(4)
    with c13:
        date_from = st.date_input("ì‹œì‘ì¼", value=default_start)
    with c14:
        date_to = st.date_input("ì¢…ë£Œì¼", value=default_end)
    with c15:
        st.write("")  # ìë¦¬ë§ì¶¤
    with c16:
        st.write("")  # ìë¦¬ë§ì¶¤

    # ---- í•„í„° ì ìš© ----
    f = df.copy()
    if plants:         f = f[f["plant"].isin(plants)]
    if lines:          f = f[f["line"].isin(lines)]
    if suppliers:      f = f[f["supplier_code"].isin(suppliers)]
    if supplier_names: f = f[f["supplier_name"].isin(supplier_names)]
    if mat_types:      f = f[f["material_type"].isin(mat_types)]
    if material_names: f = f[f["material_name"].isin(material_names)]
    if materials:      f = f[f["material_code"].isin(materials)]
    if fo_types:       f = f[f["contam_type"].isin(fo_types)]
    if severities:     f = f[f["severity"].isin(severities)]
    if origins:        f = f[f["origin"].isin(origins)]
    if imported:       f = f[f["imported"].isin(imported)]
    # ë‚ ì§œ
    f = f[(pd.to_datetime(f["dt"]) >= pd.to_datetime(date_from)) & (pd.to_datetime(f["dt"]) <= pd.to_datetime(date_to))]
    # íƒœê·¸
    mode = "ALL" if tag_mode.startswith("ALL") else "ANY"
    f = f[tag_filter_mask(f["color_tags"], selected_tags=tags, mode=mode)]

    st.session_state["filtered_df"] = f

    st.write(f"í•„í„° ê²°ê³¼: **{len(f):,}ê±´**")
    st.dataframe(f.head(200), use_container_width=True)

    # ---- í”¼ë²— ----
    st.markdown("#### í”¼ë²— í…Œì´ë¸”")
    pv_c1, pv_c2, pv_c3, pv_c4 = st.columns([1.4,1,1,1])
    with pv_c1:
        row_opts = ["plant","line","supplier_code","supplier_name","material_type","material_code","material_name","contam_type","severity","origin","imported"]
        rows = st.multiselect("í–‰(ë‹¤ì¤‘ ì„ íƒ)", row_opts)
    with pv_c2:
        col_opts = ["plant","line","supplier_code","material_type","material_code","contam_type","severity","origin","imported"]
        cols = st.multiselect("ì—´(ì„ íƒ)", col_opts)
    with pv_c3:
        agg_metric = st.selectbox("ì§€í‘œ", [
            "count í•©ê³„ (ê±´ìˆ˜)","ë ˆì½”ë“œ ìˆ˜",
            "ì´ë¬¼ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)",
            "ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)",
            "ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)"
        ])
    with pv_c4:
        chart_type = st.selectbox("ì°¨íŠ¸ ìœ í˜•", ["ë§‰ëŒ€(bar)","ì„ (line)","ì˜ì—­(area)"])

    # (íƒ­â‘  í”¼ë²—/í•„í„° ë‚´ë¶€) ì¶• ì „í™˜ í† ê¸€ ë¼ì¸ ëŒ€ì²´
    axis_toggle = st.toggle("ì°¨íŠ¸ ê°€ë¡œ/ì„¸ë¡œì¶• ì „í™˜ (ê¸°ë³¸=ê°€ë¡œí˜•)", value=True)  # False=ì„¸ë¡œí˜•, True=ê°€ë¡œí˜• ê¸°ë³¸


    def pivot_rates(frame, rows, cols, which="all"):
        """which: 'all'|'sev'|'norm' -> (sum count)/sum selection_amount_kg"""
        grp = rows + (cols if cols else [])
        denom = frame.groupby(grp)["selection_amount_kg"].sum()
        if which == "all":
            num = frame.groupby(grp)["count"].sum()
        elif which == "sev":
            num = frame.assign(_num=np.where(frame["severity"]=="ì¤‘ëŒ€", frame["count"], 0)).groupby(grp)["_num"].sum()
        else:  # 'norm'
            num = frame.assign(_num=np.where(frame["severity"]=="ì¼ë°˜", frame["count"], 0)).groupby(grp)["_num"].sum()
        rate = (num / denom.replace(0, np.nan)).fillna(0.0)
        if cols:
            return rate.unstack(cols).fillna(0.0)
        else:
            return rate.to_frame("value")

    pt = None
    if rows:
        g = f.copy()
        if agg_metric.startswith("count"):
            if agg_metric.startswith("count í•©ê³„"):
                values = "count"; aggfunc = "sum"
            else:
                g["__one__"] = 1; values = "__one__"; aggfunc = "sum"
            if cols:
                pt = pd.pivot_table(g, index=rows, columns=cols, values=values, aggfunc=aggfunc, fill_value=0)
            else:
                pt = g.groupby(rows)[values].sum().to_frame("value")
        else:
            if "ì´ë¬¼ìˆ˜ì¤€" in agg_metric:
                pt = pivot_rates(g, rows, cols, which="all")
            elif "ì¤‘ëŒ€ì´ë¬¼" in agg_metric:
                pt = pivot_rates(g, rows, cols, which="sev")
            else:
                pt = pivot_rates(g, rows, cols, which="norm")

        st.session_state["pivot_df"] = pt
        st.dataframe(pt, use_container_width=True)

        # ---- í”¼ë²— ì°¨íŠ¸ (Altair + ì¶• ì „í™˜) ----
        st.markdown("##### í”¼ë²— ì°¨íŠ¸")
        chart_df = pt.copy()
        if isinstance(chart_df, pd.Series):
            chart_df = chart_df.to_frame("value")
        if isinstance(chart_df.index, pd.MultiIndex):
            chart_df.index = flatten_index(chart_df.index)
        if isinstance(chart_df.columns, pd.MultiIndex):
            chart_df.columns = flatten_index(chart_df.columns)
        chart_df = chart_df.reset_index().rename(columns={"index":"row"})
        # í­ ì œí•œ
        if chart_df.shape[0] > 2000:
            st.caption("âš ï¸ ì°¨íŠ¸ ì„±ëŠ¥ì„ ìœ„í•´ ìƒìœ„ 2000 ì…€ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
            chart_df = chart_df.head(2000)

        # wide->long
        chart_long = chart_df.melt(id_vars=chart_df.columns[0], var_name="col", value_name="val")
        row_field = chart_df.columns[0]

        base = alt.Chart(chart_long).transform_filter(alt.datum.val != None)
        if axis_toggle:
            enc = base.mark_bar().encode(
                x=alt.X("val:Q", title="ê°’"),
                y=alt.Y(f"{row_field}:N", title="í–‰"),
                color=alt.Color("col:N", title="ì—´", legend=alt.Legend(columns=2))
            )
        else:
            enc = base.mark_bar().encode(
                x=alt.X(f"{row_field}:N", title="í–‰"),
                y=alt.Y("val:Q", title="ê°’"),
                color=alt.Color("col:N", title="ì—´", legend=alt.Legend(columns=2))
            )

        if chart_type.startswith("ì„ "):
            enc = enc.mark_line(point=True)
        elif chart_type.startswith("ì˜ì—­"):
            enc = enc.mark_area(opacity=0.6)

        st.altair_chart(enc.properties(height=420), use_container_width=True)
    else:
        st.info("í–‰ ì°¨ì›ì„ 1ê°œ ì´ìƒ ì„ íƒí•˜ë©´ í”¼ë²—ì´ ìƒì„±ë©ë‹ˆë‹¤.")

# -----------------------------
# â‘¡ ê²½ë³´ ë³´ë“œ (V5: rate ê¸°ë°˜)
# -----------------------------
with tab2:
    st.subheader("ì‹ ê·œ ì´ë¬¼ / ê¸‰ì¦ ê²½ë³´ ë³´ë“œ (ì´ë¬¼ìˆ˜ì¤€ ê¸°ë°˜)")

    # ì‹ ê·œ ì´ë¬¼
    with st.expander("ì‹ ê·œ ì´ë¬¼ ë°œìƒ (ì¡°í•©: ê³µê¸‰ì‚¬+ì›ë£Œ)", expanded=True):
        nov_df = detect_novel_types(st.session_state["filtered_df"])
        nov_view = nov_df[nov_df["is_novel_type"]].sort_values("dt", ascending=False)
        st.session_state["alerts_novel"] = nov_view
        st.write(f"ì‹ ê·œ ìœ í˜• ë°œìƒ ê±´ìˆ˜: **{len(nov_view):,}**")
        st.dataframe(nov_view.head(200), use_container_width=True)

    # ê¸‰ì¦/í•˜ë½ (rate-based)
    with st.expander(f"ê¸‰ì¦/í•˜ë½ íƒì§€ (ìµœê·¼ {DEFAULT_RECENT_DAYS}ì¼ vs ê³¼ê±° {DEFAULT_BASELINE_DAYS}ì¼, zâ‰¥Â±{SURGE_Z_THRESHOLD})", expanded=True):
        surge_df = rate_change_flag_v5(
            st.session_state["filtered_df"],
            recent_days=int(DEFAULT_RECENT_DAYS),
            baseline_days=int(DEFAULT_BASELINE_DAYS),
        )
        st.session_state["alerts_surge"] = surge_df
        if surge_df is not None and not surge_df.empty:
            st.write(f"ë¶„ì„ ëŒ€ìƒ ì¡°í•© ìˆ˜: **{len(surge_df):,}**")
            st.dataframe(
                surge_df[["supplier_code","material_code","contam_type","x_cnt","x_exp","x_rate","b_cnt","b_exp","b_rate","expected_recent_rate","z","flag"]].head(200),
                use_container_width=True
            )

            s1, s2, s3 = st.columns(3)
            with s1: st.metric("ìƒìŠ¹ ê²½ë³´", int((surge_df["flag"]=="ìƒìŠ¹").sum()))
            with s2: st.metric("í•˜ë½ ê°ì§€", int((surge_df["flag"]=="í•˜ë½").sum()))
            with s3: st.metric("ì •ìƒ", int((surge_df["flag"]=="ì •ìƒ").sum()))

        # ----- ì—¬ê¸°ë¶€í„° êµì²´: ì„ íƒ í•­ëª© ê·¸ë˜í”„ (ìµœê·¼ 180ì¼ 'ì´ë¬¼ìˆ˜ì¤€' ì‹œê³„ì—´) -----
        st.markdown("##### ì„ íƒ í•­ëª© ê·¸ë˜í”„ (ìµœê·¼ 180ì¼ ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€ + b/expected/x rate ì„ )")

        view_df = surge_df.head(200).copy()
        view_df["key"] = view_df["supplier_code"] + " | " + view_df["material_code"] + " | " + view_df["contam_type"]
        sel = st.selectbox("í•­ëª© ì„ íƒ (ê³µê¸‰ì‚¬ | ì›ë£Œ | ìœ í˜•)", options=view_df["key"].tolist())
        srow = view_df[view_df["key"]==sel].iloc[0]

        # ìµœê·¼ 180ì¼ ë²”ìœ„
        f2 = st.session_state["filtered_df"].copy()
        today = pd.to_datetime(f2["dt"]).max().date()
        base_start = today - timedelta(days=DEFAULT_BASELINE_DAYS-1)

        # í•´ë‹¹ ì¡°í•© ë°ì´í„° í•„í„°
        mask = (
            (f2["supplier_code"] == srow["supplier_code"]) &
            (f2["material_code"]  == srow["material_code"]) &
            (f2["contam_type"]    == srow["contam_type"]) &
            (pd.to_datetime(f2["dt"]).dt.date >= base_start) &
            (pd.to_datetime(f2["dt"]).dt.date <= today)
)

        ts = f2.loc[mask, ["dt","count","selection_amount_kg"]].copy()
        ts["dt"] = pd.to_datetime(ts["dt"]).dt.date

        # ì¼ì¼ í•©ì‚° (ë¶„ì/ë¶„ëª¨)
        daily = (
        ts.groupby("dt")[["count","selection_amount_kg"]]
            .sum()
              .reindex([base_start + timedelta(days=i) for i in range(DEFAULT_BASELINE_DAYS)], fill_value=0)
            .reset_index()
            .rename(columns={"index":"dt"})
)
        # ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€ = sum(count)/sum(kg)
        daily["daily_rate"] = np.where(daily["selection_amount_kg"]>0,
                                       daily["count"]/daily["selection_amount_kg"], 0.0)

        # ê¸°ì¤€ì„ /ê¸°ëŒ€/ìµœê·¼ rate (ì „ê¸°ê°„ ë™ì¼ ê°’ì˜ 'ìˆ˜í‰ì„ 'ì„ ì‹œê³„ì—´ë¡œ í‘œí˜„)
        b_rate  = float(srow.get("b_rate", 0.0))
        exp_rate = float(srow.get("expected_recent_rate", b_rate))
        x_rate  = float(srow.get("x_rate", 0.0))

        lines_df = pd.DataFrame({
            "dt": list(daily["dt"])*3,
            "value": [b_rate]*len(daily) + [exp_rate]*len(daily) + [x_rate]*len(daily),
            "type": (["ê¸°ì¤€ì„  b_rate"]*len(daily)) + (["ìµœê·¼ ê¸°ëŒ€ expected_rate"]*len(daily)) + (["ìµœê·¼ ì‹¤ì¸¡ x_rate"]*len(daily))
})

        # ìµœê·¼ 7ì¼ í•˜ì´ë¼ì´íŠ¸ ë°´ë“œ
        recent_start = today - timedelta(days=DEFAULT_RECENT_DAYS-1)
        band = alt.Chart(pd.DataFrame({"start":[recent_start], "end":[today]})).mark_rect(
            opacity=0.08, color="#E53935"
        ).encode(x="start:T", x2="end:T")

        # ì‚°ì ë„(ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€)
        points = alt.Chart(daily).mark_circle(size=40, opacity=0.65).encode(
            x=alt.X("dt:T", title="ì¼ì"),
            y=alt.Y("daily_rate:Q", title="ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€ (count/kg)", axis=alt.Axis(format=".4f"))
)

        # ì„ (b_rate / expected_recent_rate / x_rate)
        lines = alt.Chart(lines_df).mark_line(size=2).encode(
            x="dt:T",
            y=alt.Y("value:Q", title="ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€ (count/kg)", axis=alt.Axis(format=".4f")),
            color=alt.Color("type:N", title=None)
)

        st.altair_chart((band + points + lines).properties(height=360), use_container_width=True)
        st.caption("â€¢ ì : ìµœê·¼ 180ì¼ì˜ ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€(ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)  â€¢ ì„ : b_rate / expected_recent_rate / x_rate (ê¸°ê°„ ì „ì²´ ë™ì¼ ê°’)")

# -----------------------------
# â‘¢ ì•¡ì…˜ í…œí”Œë¦¿ (í™”ë©´ ì¶œë ¥ + ë³µì‚¬ + txt)
# -----------------------------
with tab3:
    st.subheader("ì•¡ì…˜ í…œí”Œë¦¿ ìƒì„±")

    surge_all = st.session_state.get("alerts_surge", pd.DataFrame())
    novel_view = st.session_state.get("alerts_novel", pd.DataFrame())

    if surge_all is None or surge_all.empty:
        st.info("ê²½ë³´ ë³´ë“œì—ì„œ ê²°ê³¼ê°€ ìƒì„±ëœ í›„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        # ì •ìƒ ì œì™¸ + |z| ë‚´ë¦¼ì°¨ìˆœ
        non_normal = surge_all[surge_all["flag"]!="ì •ìƒ"].copy()
        if non_normal.empty:
            st.info("ìƒìŠ¹/í•˜ë½ ê²½ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            non_normal["abs_z"] = non_normal["z"].abs()
            top_n = st.slider("ì•Œë¦¼ ìƒìœ„ N(|z| ê¸°ì¤€)", min_value=5, max_value=100, value=20, step=5)
            top_df = non_normal.sort_values("abs_z", ascending=False).head(top_n)

            today_str = datetime.now().strftime("%Y-%m-%d")
            intro = f"[ìë™ìƒì„±] ì´ë¬¼ìˆ˜ì¤€ ê¸‰ì¦/í•˜ë½Â·ì‹ ê·œ ìœ í˜• ëª¨ë‹ˆí„°ë§ ì•Œë¦¼ â€“ {today_str}\n"

            lines_out = []
            for _, r in top_df.iterrows():
                key = f"{r.get('supplier_code','')}-{r.get('material_code','')}-{r.get('contam_type','')}"
                lines_out.append(
                    f"â€¢ {key}: ìµœê·¼ rate={r.get('x_rate',0):.4f}, ê¸°ì¤€ì„  rate={r.get('b_rate',0):.4f}, z={r.get('z',0):.2f}, íŒì •={r.get('flag','')}"
                )
            summary = "\n".join(lines_out[:200])

            novel_lines = []
            if novel_view is not None and not novel_view.empty:
                for _, r in novel_view.head(20).iterrows():
                    key = f"{r.get('supplier_code','')}-{r.get('material_code','')}"
                    novel_lines.append(f"â€¢ [ì‹ ê·œ] {key}ì—ì„œ '{r.get('contam_type','')}' ìµœì´ˆ ë°œìƒ @ {r.get('dt')}")
            novel_text = "\n".join(novel_lines)

            guidance = (
                "\n[ê¶Œê³  ì•¡ì…˜]\n"
                "- ê³µì • ì„ ë³„ê°•ë„ ìƒí–¥ ë° í•´ë‹¹ LOT ì¶”ê°€ê²€ì‚¬\n"
                "- ê³µê¸‰ì‚¬ ì›ì¸ì ê²€ ìš”ì²­(ì‚¬ì§„/ì¦ë¹™ ì²¨ë¶€)\n"
                "- (ì„ê³„ ì´ˆê³¼ ì‹œ) ì›ë£Œ LOT Hold ë° ê´€ë ¨ ì œí’ˆ LOT ì¶œê³ ì¤‘ì§€ ê²€í† \n"
                "- CAPA ë“±ë¡ ë° ì¬ë°œë°©ì§€ ì¶”ì "
            )

            email_text = intro + "\n[ê¸‰ì¦Â·í•˜ë½ ìƒìœ„ ìš”ì•½]\n" + summary + ("\n\n[ì‹ ê·œ ì´ë¬¼ ê°ì§€]\n" + novel_text if novel_text else "") + guidance

            st.markdown("#### ğŸ“£ ë°œì†¡/ê³µìœ ìš© ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°")
            st.text_area("ë³¸ë¬¸", value=email_text, height=300)

            # ë³µì‚¬ ë²„íŠ¼
            components.html(
                f"""
                <button onclick="navigator.clipboard.writeText({email_text!r});
                                 const s=this; s.innerText='ë³µì‚¬ë¨!'; setTimeout(()=>s.innerText='í´ë¦½ë³´ë“œë¡œ ë³µì‚¬',1200);"
                        style="padding:8px 14px; border-radius:8px; border:1px solid #ddd; cursor:pointer;">
                    í´ë¦½ë³´ë“œë¡œ ë³µì‚¬
                </button>
                """,
                height=60
            )
            st.download_button("ë³¸ë¬¸ .txt ë‹¤ìš´ë¡œë“œ", data=email_text.encode("utf-8-sig"), file_name="alert_message.txt")

# -----------------------------
# â‘£ ë‚´ë³´ë‚´ê¸° (CSV/XLSX)
# -----------------------------
with tab4:
    st.subheader("ê²°ê³¼ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°")

    f = st.session_state.get("filtered_df", pd.DataFrame())
    pv = st.session_state.get("pivot_df", None)
    nov = st.session_state.get("alerts_novel", pd.DataFrame())
    surge = st.session_state.get("alerts_surge", pd.DataFrame())

    if not f.empty:
        st.download_button("í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=f.to_csv(index=False).encode("utf-8-sig"), file_name="filtered_incidents.csv")
    else:
        st.info("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (íƒ­â‘ ì—ì„œ ì¡°ê±´ì„ ì¡°ì •í•˜ì„¸ìš”)")

    # XLSX ì—”ì§„ í´ë°± (XlsxWriter -> openpyxl)
    try:
        import xlsxwriter  # noqa
        engine = "xlsxwriter"
    except Exception:
        engine = "openpyxl"

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine=engine) as writer:
        if not f.empty:
            f.to_excel(writer, sheet_name="FilteredData", index=False)
            try:
                writer.sheets["FilteredData"].freeze_panes(1,0)
            except Exception:
                pass
        if pv is not None:
            pv_out = pv.copy()
            if isinstance(pv_out, pd.Series):
                pv_out = pv_out.to_frame("value")
            if isinstance(pv_out.index, pd.MultiIndex):
                pv_out.index = [' | '.join(map(str, t)) for t in pv_out.index]
            if isinstance(pv_out.columns, pd.MultiIndex):
                pv_out.columns = [' | '.join(map(str, t)) for t in pv_out.columns]
            pv_out.to_excel(writer, sheet_name="Pivot", merge_cells=False)
            try:
                writer.sheets["Pivot"].freeze_panes(1,1)
            except Exception:
                pass
        if nov is not None and not nov.empty:
            nov.to_excel(writer, sheet_name="NovelAlerts", index=False)
            try:
                writer.sheets["NovelAlerts"].freeze_panes(1,0)
            except Exception:
                pass
        if surge is not None and not surge.empty:
            surge.to_excel(writer, sheet_name="SurgeAlerts", index=False)
            try:
                writer.sheets["SurgeAlerts"].freeze_panes(1,0)
            except Exception:
                pass

    st.download_button("ì—‘ì…€ ë³´ê³ ì„œ(XLSX) ë‹¤ìš´ë¡œë“œ", data=output.getvalue(), file_name="FOCast_report.xlsx")

st.caption("â€» ê³ ë„í™”: rate ì„ê³„ì¹˜ ì •ì±…/ê°€ì¤‘, LOTâ†”ì œí’ˆ íŠ¸ë ˆì´ìŠ¤, ìë™ ë©”ì¼/Teams ì „ì†¡(Graph API) ë“± í™•ì¥ ê°€ëŠ¥.")
