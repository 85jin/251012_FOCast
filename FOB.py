# FOB.py (v0.2)
# Streamlit ì›¹ì•±: ì´ë¬¼(FO) ë¶„ì„/ì•Œë¦¼ "ì—ì´ìŠ¤"
# v0.2 ë³€ê²½:
#  - í•„í„° 4ì—´ ê·¸ë¦¬ë“œ, imported/origin/severity í•„í„°Â·í”¼ë²— ì°¨ì› ì¶”ê°€
#  - ë‚ ì§œ ê¸°ë³¸ê°’: ì‹œì‘=ì˜¤ëŠ˜-1ë…„, ì¢…ë£Œ=ì˜¤ëŠ˜
#  - í”¼ë²— ì§€í‘œ: ì´ë¬¼ìˆ˜ì¤€ / ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€ / ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€ (ë¶„ìí•©/ë¶„ëª¨í•©)
#  - ì•¡ì…˜ í…œí”Œë¦¿: flag == "ì •ìƒ" ì œì™¸, |z| ë‚´ë¦¼ì°¨ìˆœ ìƒìœ„ N

import io
from datetime import datetime, timedelta, date

import numpy as np
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components

# -----------------------------
# ì „ì—­ ì„¤ì • ë° ìƒìˆ˜
# -----------------------------
st.set_page_config(page_title="í¬ì¼€ìŠ¤íŠ¸ - ì´ë¬¼ ë¶„ì„Â·ì•Œë¦¼", layout="wide", initial_sidebar_state="expanded")
APP_TITLE = "í¬ì¼€ìŠ¤íŠ¸ (FOCast) â€“ ì´ë¬¼ ë¶„ì„Â·ì•Œë¦¼ ì›¹ì•±"
SECRET_CODE = "cj123456"  # ì£¼ê¸°ì  ë³€ê²½ ì˜ˆì •

# v4 ìŠ¤í‚¤ë§ˆ ë°˜ì˜ (stage ì œê±°, ì‹ ê·œ ì—´ ì¶”ê°€)
REQUIRED_COLUMNS = [
    "dt","plant","line",
    "material_code","material_name",
    "supplier_code","supplier_name",
    "contam_type","color_tags",
    "count","unit","lot_no","severity",
    "photo_url","notes",
    "origin","imported",
    "selection_amount_kg",
    "ì´ë¬¼ìˆ˜ì¤€","ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€","ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"
]

DEFAULT_RECENT_DAYS = 7
DEFAULT_BASELINE_DAYS = 180
SURGE_Z_THRESHOLD = 3.0  # z >= 3 ìƒìŠ¹, z <= -3 í•˜ë½

# -----------------------------
# ì¸ì¦
# -----------------------------
def auth_gate():
    st.markdown("### ğŸ” ë³´ì•ˆì½”ë“œ ì…ë ¥")
    with st.form("auth_form", clear_on_submit=False):
        code = st.text_input("ë³´ì•ˆì½”ë“œ", type="password", help="ì ‘ì† ë³´ì•ˆì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        ok = st.form_submit_button("ì ‘ì†")
        if ok:
            if code == SECRET_CODE:
                st.session_state["_authed"] = True
                st.success("ì ‘ì† í—ˆìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.session_state["_authed"] = False
                st.error("ë³´ì•ˆì½”ë“œê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

if "_authed" not in st.session_state:
    st.session_state["_authed"] = False

st.title(APP_TITLE)

if not st.session_state["_authed"]:
    auth_gate()
    st.stop()

# -----------------------------
# ìœ í‹¸ & ì „ì²˜ë¦¬
# -----------------------------
@st.cache_data(show_spinner=False)
def load_file(uploaded_file, sheet_name=None) -> pd.DataFrame:
    """CSV/Excel íŒŒì¼ ë¡œë“œ"""
    name = uploaded_file.name.lower()
    if name.endswith(".csv"):
        df = pd.read_csv(uploaded_file)
    elif name.endswith(".xlsx") or name.endswith(".xls"):
        df = pd.read_excel(uploaded_file, sheet_name=sheet_name if sheet_name else None, engine="openpyxl")
    else:
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” Excel(.xlsx/.xls)ë§Œ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    return df

def ensure_columns(df: pd.DataFrame) -> pd.DataFrame:
    """í•„ìˆ˜ ì»¬ëŸ¼/íƒ€ì… ë³´ì • (v4 ìŠ¤í‚¤ë§ˆ ëŒ€ì‘)"""
    # ëˆ„ë½ ì»¬ëŸ¼ ë³´ê°•
    for col in REQUIRED_COLUMNS:
        if col not in df.columns:
            df[col] = np.nan

    # dt (ë‚ ì§œ) íŒŒì‹±: v4ëŠ” ë‚ ì§œê¹Œì§€ë§Œ ì¡´ì¬
    try:
        df["dt"] = pd.to_datetime(df["dt"]).dt.date
    except Exception:
        df["dt"] = pd.to_datetime(df["dt"], errors="coerce").dt.date

    # ìˆ«ìí˜•
    for c in ["count", "selection_amount_kg", "ì´ë¬¼ìˆ˜ì¤€", "ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€", "ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    df["count"] = df["count"].fillna(0).astype(int)
    df["selection_amount_kg"] = df["selection_amount_kg"].fillna(0).astype(int)
    for c in ["ì´ë¬¼ìˆ˜ì¤€","ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€","ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"]:
        df[c] = df[c].fillna(0.0).astype(float)

    # ë¬¸ìì—´í˜•
    str_cols = [
        "plant","line","material_code","material_name",
        "supplier_code","supplier_name","contam_type",
        "color_tags","unit","lot_no","severity",
        "photo_url","notes","origin","imported"
    ]
    for c in str_cols:
        df[c] = df[c].fillna("").astype(str)

    return df

def split_tags(s: str):
    if not isinstance(s, str):
        return []
    return [t.strip() for t in s.split(";") if t.strip()]

def tag_filter_mask(series_tags: pd.Series, selected_tags, mode="ANY"):
    if not selected_tags:
        return pd.Series([True]*len(series_tags), index=series_tags.index)
    row_tags = series_tags.apply(split_tags)
    if mode == "ALL":
        mask = row_tags.apply(lambda lst: all(t in lst for t in selected_tags))
    else:
        mask = row_tags.apply(lambda lst: any(t in lst for t in selected_tags))
    return mask

def flatten_index(idx):
    if hasattr(idx, "names") and isinstance(idx, pd.MultiIndex):
        return [" | ".join(map(str, tup)) for tup in idx.to_list()]
    return [str(x) for x in idx]

# -----------------------------
# ë¶„ì„ í•¨ìˆ˜
# -----------------------------
def detect_novel_types(df: pd.DataFrame,
                       key_cols=("supplier_code","material_code"),
                       type_col="contam_type",
                       time_col="dt") -> pd.DataFrame:
    f = df[[*key_cols, type_col, time_col]].copy()
    f = f.sort_values(time_col)
    seen, flags = {}, []
    for _, row in f.iterrows():
        key = tuple(row[c] for c in key_cols)
        t = row[type_col]
        if key not in seen:
            seen[key] = set()
        novel = t not in seen[key]
        flags.append(novel)
        seen[key].add(t)
    f["is_novel_type"] = flags
    return f

def rate_change_flag(df: pd.DataFrame,
                     key_cols=("supplier_code","material_code","contam_type"),
                     count_col="count",
                     time_col="dt",
                     recent_days=DEFAULT_RECENT_DAYS,
                     baseline_days=DEFAULT_BASELINE_DAYS) -> pd.DataFrame:
    # dtê°€ date í˜•ì‹ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    g = df[[*key_cols, count_col, time_col]].copy()
    g["date"] = g[time_col]  # already date
    if g["date"].isna().all():
        return pd.DataFrame()

    today = max([d for d in g["date"] if pd.notna(d)], default=None)
    if pd.isna(today) or today is None:
        return pd.DataFrame()

    recent_start = today - timedelta(days=recent_days-1)
    base_end = recent_start - timedelta(days=1)
    base_start = base_end - timedelta(days=baseline_days-1)

    recent = g[(g["date"]>=recent_start) & (g["date"]<=today)]
    base   = g[(g["date"]>=base_start) & (g["date"]<=base_end)]

    if recent.empty and base.empty:
        return pd.DataFrame()

    r = recent.groupby(list(key_cols))[count_col].sum().rename("x").reset_index()
    b = base.groupby(list(key_cols))[count_col].sum().rename("base_count").reset_index()

    merged = pd.merge(r, b, on=list(key_cols), how="outer").fillna(0)
    daily_base = merged["base_count"] / max(baseline_days, 1)
    E = daily_base * recent_days
    z = (merged["x"] - E) / np.sqrt(E + 1e-6)
    merged["expected_recent"] = E
    merged["z"] = z
    merged["flag"] = np.select([z >= SURGE_Z_THRESHOLD, z <= -SURGE_Z_THRESHOLD], ["ìƒìŠ¹","í•˜ë½"], default="ì •ìƒ")
    merged = merged.sort_values("z", ascending=False)
    return merged

# -----------------------------
# ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ
# -----------------------------
with st.sidebar:
    st.header("â‘  ë°ì´í„° ì—…ë¡œë“œ")
    uploaded = st.file_uploader("ì—‘ì…€/CSV ì—…ë¡œë“œ", type=["csv","xlsx","xls"])
    sheet_name = st.text_input("ì—‘ì…€ ì‹œíŠ¸ëª…(ì˜µì…˜)", value="")
    st.header("â‘¡ íƒœê·¸ ë§¤ì¹­")
    tag_mode = st.radio("íƒœê·¸ ëª¨ë“œ", ["ANY(í•˜ë‚˜ë¼ë„ ì¼ì¹˜)","ALL(ëª¨ë‘ í¬í•¨)"], index=0)
    st.caption("ğŸ’¡ ì—…ë¡œë“œ í›„ ìƒë‹¨ íƒ­ì—ì„œ í”¼ë²—/ê²½ë³´/ì•¡ì…˜/ë‚´ë³´ë‚´ê¸°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

if uploaded is None:
    st.info("ì™¼ìª½ì—ì„œ CSV ë˜ëŠ” ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (v4 ìŠ¤í‚¤ë§ˆ ê¶Œì¥)")
    st.stop()

try:
    df_raw = load_file(uploaded, sheet_name=sheet_name if sheet_name.strip() else None)
except Exception as e:
    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
    st.stop()

df = ensure_columns(df_raw)

min_dt = pd.to_datetime(df["dt"]).min()
max_dt = pd.to_datetime(df["dt"]).max()

# -----------------------------
# ìƒë‹¨ KPI
# -----------------------------
k1,k2,k3,k4 = st.columns(4)
with k1:
    st.metric("ì´ ê±´ìˆ˜", f"{len(df):,}")
with k2:
    st.metric("ê³ ìœ  ì›ë£Œì½”ë“œ", df["material_code"].nunique())
with k3:
    st.metric("ê³µê¸‰ì‚¬ ìˆ˜", df["supplier_code"].nunique())
with k4:
    st.metric("ê¸°ê°„ ë²”ìœ„", f"{min_dt} ~ {max_dt}" if pd.notna(min_dt) else "-")

# íƒ­ ìƒíƒœ
st.session_state.setdefault("pivot_df", None)
st.session_state.setdefault("alerts_novel", None)
st.session_state.setdefault("alerts_surge", None)
st.session_state.setdefault("filtered_df", None)

# -----------------------------
# íƒ­ êµ¬ì„±
# -----------------------------
tab1, tab2, tab3, tab4 = st.tabs([
    "â‘  í”¼ë²—/í•„í„° ê²€ìƒ‰", "â‘¡ ê²½ë³´ ë³´ë“œ", "â‘¢ ì•¡ì…˜ í…œí”Œë¦¿", "â‘£ ë‚´ë³´ë‚´ê¸°"
])

# -----------------------------
# â‘  í”¼ë²—/í•„í„° ê²€ìƒ‰
# -----------------------------
with tab1:
    st.subheader("í”¼ë²—/í•„í„° ê²€ìƒ‰")

    # ---- í•„í„° (4ê°œì”© ë°°ì¹˜) ----
    today_d = date.today()
    default_start = today_d - timedelta(days=365)
    default_end = today_d

    # 1í–‰
    c1,c2,c3,c4 = st.columns(4)
    with c1:
        plants = st.multiselect("ê³µì¥(plant)", sorted([p for p in df["plant"].unique() if p!=""]))
    with c2:
        lines = st.multiselect("ë¼ì¸(line)", sorted([p for p in df["line"].unique() if p!=""]))
    with c3:
        suppliers = st.multiselect("ê³µê¸‰ì‚¬ ì½”ë“œ(supplier_code)", sorted([p for p in df["supplier_code"].unique() if p!=""]), key="supplier_select")
    with c4:
        # suppliersì— ë”°ë¼ material í›„ë³´ ì œí•œ
        if suppliers:
            mat_opts = sorted(df[df["supplier_code"].isin(suppliers)]["material_code"].dropna().unique())
        else:
            mat_opts = sorted(df["material_code"].dropna().unique())
        # ì´ì „ ì„ íƒ ìœ ì§€
        prev_selected = st.session_state.get("material_select", [])
        valid_prev = [m for m in prev_selected if m in mat_opts]
        materials = st.multiselect("ì›ë£Œ ì½”ë“œ(material_code)", mat_opts, default=valid_prev, key="material_select")

    # 2í–‰
    c5,c6,c7,c8 = st.columns(4)
    with c5:
        fo_types = st.multiselect("ì´ë¬¼ ìœ í˜•(contam_type)", sorted([p for p in df["contam_type"].unique() if p!=""]))
    with c6:
        severities = st.multiselect("ì¤‘ëŒ€/ì¼ë°˜(severity)", ["ì¤‘ëŒ€","ì¼ë°˜"])
    with c7:
        origins = st.multiselect("ì›ì‚°ì§€(origin)", sorted([p for p in df["origin"].unique() if p!=""]))
    with c8:
        imported = st.multiselect("ìˆ˜ì…ì—¬ë¶€(imported)", sorted([p for p in df["imported"].unique() if p!=""]))

    # 3í–‰
    c9,c10,c11,c12 = st.columns(4)
    with c9:
        unique_tags = sorted({t for row in df["color_tags"] for t in split_tags(row)})
        tags = st.multiselect("íƒœê·¸(color_tags)", unique_tags)
    with c10:
        date_from = st.date_input("ì‹œì‘ì¼", value=default_start)
    with c11:
        date_to = st.date_input("ì¢…ë£Œì¼", value=default_end)
    with c12:
        st.write("")  # ìë¦¬ë§ì¶¤

    # ---- í•„í„° ì ìš© ----
    f = df.copy()
    if plants:    f = f[f["plant"].isin(plants)]
    if lines:     f = f[f["line"].isin(lines)]
    if suppliers: f = f[f["supplier_code"].isin(suppliers)]
    if materials: f = f[f["material_code"].isin(materials)]
    if fo_types:  f = f[f["contam_type"].isin(fo_types)]
    if severities:f = f[f["severity"].isin(severities)]
    if origins:   f = f[f["origin"].isin(origins)]
    if imported:  f = f[f["imported"].isin(imported)]
    # ë‚ ì§œ
    f = f[(pd.to_datetime(f["dt"]) >= pd.to_datetime(date_from)) & (pd.to_datetime(f["dt"]) <= pd.to_datetime(date_to))]
    # íƒœê·¸
    mode = "ALL" if tag_mode.startswith("ALL") else "ANY"
    f = f[tag_filter_mask(f["color_tags"], selected_tags=tags, mode=mode)]

    st.session_state["filtered_df"] = f

    st.write(f"í•„í„° ê²°ê³¼: **{len(f):,}ê±´**")
    st.dataframe(f.head(200), use_container_width=True)

    # ---- í”¼ë²— ----
    st.markdown("#### í”¼ë²— í…Œì´ë¸”")
    pv_c1, pv_c2, pv_c3, pv_c4 = st.columns([1.4,1,1,1])
    with pv_c1:
        row_opts = ["plant","line","supplier_code","supplier_name","material_code","material_name","contam_type","severity","origin","imported"]
        rows = st.multiselect("í–‰(ë‹¤ì¤‘ ì„ íƒ)", row_opts)
    with pv_c2:
        col_opts = ["plant","line","supplier_code","material_code","contam_type","severity","origin","imported"]
        cols = st.multiselect("ì—´(ì„ íƒ)", col_opts)
    with pv_c3:
        agg_metric = st.selectbox("ì§€í‘œ", [
            "count í•©ê³„ (ê±´ìˆ˜)","ë ˆì½”ë“œ ìˆ˜",
            "ì´ë¬¼ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)",
            "ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)",
            "ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)"
        ])
    with pv_c4:
        chart_type = st.selectbox("ì°¨íŠ¸ ìœ í˜•", ["ë§‰ëŒ€(bar)","ì„ (line)","ì˜ì—­(area)"])

    def pivot_rates(frame, rows, cols, which="all"):
        """which: 'all'|'sev'|'norm' -> (sum count)/sum selection_amount_kg"""
        grp = rows + (cols if cols else [])
        denom = frame.groupby(grp)["selection_amount_kg"].sum()
        if which == "all":
            num = frame.groupby(grp)["count"].sum()
        elif which == "sev":
            num = frame.assign(_num=np.where(frame["severity"]=="ì¤‘ëŒ€", frame["count"], 0)).groupby(grp)["_num"].sum()
        else:  # 'norm'
            num = frame.assign(_num=np.where(frame["severity"]=="ì¼ë°˜", frame["count"], 0)).groupby(grp)["_num"].sum()
        rate = (num / denom.replace(0, np.nan)).fillna(0.0)
        if cols:
            return rate.unstack(cols).fillna(0.0)
        else:
            return rate.to_frame("value")

    pt = None
    if rows:
        g = f.copy()
        if agg_metric.startswith("count"):
            if agg_metric.startswith("count í•©ê³„"):
                values = "count"; aggfunc = "sum"
            else:
                g["__one__"] = 1; values = "__one__"; aggfunc = "sum"
            if cols:
                pt = pd.pivot_table(g, index=rows, columns=cols, values=values, aggfunc=aggfunc, fill_value=0)
            else:
                pt = g.groupby(rows)[values].sum().to_frame("value")
        else:
            if "ì´ë¬¼ìˆ˜ì¤€" in agg_metric:
                pt = pivot_rates(g, rows, cols, which="all")
            elif "ì¤‘ëŒ€ì´ë¬¼" in agg_metric:
                pt = pivot_rates(g, rows, cols, which="sev")
            else:
                pt = pivot_rates(g, rows, cols, which="norm")

        st.session_state["pivot_df"] = pt
        st.dataframe(pt, use_container_width=True)

        # ---- í”¼ë²— ì°¨íŠ¸ ----
        st.markdown("##### í”¼ë²— ì°¨íŠ¸")
        chart_df = pt.copy()
        if isinstance(chart_df, pd.Series):
            chart_df = chart_df.to_frame("value")
        if isinstance(chart_df.index, pd.MultiIndex):
            chart_df.index = flatten_index(chart_df.index)
        if isinstance(chart_df.columns, pd.MultiIndex):
            chart_df.columns = flatten_index(chart_df.columns)
        if chart_df.shape[0] > 50:
            st.caption("âš ï¸ ì°¨íŠ¸ ì„±ëŠ¥ì„ ìœ„í•´ ìƒìœ„ 50í–‰ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
            chart_df = chart_df.head(50)

        if chart_type.startswith("ë§‰ëŒ€"):
            st.bar_chart(chart_df, use_container_width=True)
        elif chart_type.startswith("ì„ "):
            st.line_chart(chart_df, use_container_width=True)
        else:
            st.area_chart(chart_df, use_container_width=True)
    else:
        st.info("í–‰ ì°¨ì›ì„ 1ê°œ ì´ìƒ ì„ íƒí•˜ë©´ í”¼ë²—ì´ ìƒì„±ë©ë‹ˆë‹¤.")

# -----------------------------
# â‘¡ ê²½ë³´ ë³´ë“œ
# -----------------------------
with tab2:
    st.subheader("ì‹ ê·œ ì´ë¬¼ / ê¸‰ì¦ ê²½ë³´ ë³´ë“œ")

    # ì‹ ê·œ ì´ë¬¼
    with st.expander("ì‹ ê·œ ì´ë¬¼ ë°œìƒ (ì¡°í•©: ê³µê¸‰ì‚¬+ì›ë£Œ)", expanded=True):
        nov_df = detect_novel_types(st.session_state["filtered_df"])
        nov_view = nov_df[nov_df["is_novel_type"]].sort_values("dt", ascending=False)
        st.session_state["alerts_novel"] = nov_view
        st.write(f"ì‹ ê·œ ìœ í˜• ë°œìƒ ê±´ìˆ˜: **{len(nov_view):,}**")
        st.dataframe(nov_view.head(200), use_container_width=True)

    # ê¸‰ì¦/í•˜ë½
    with st.expander(f"ê¸‰ì¦/í•˜ë½ íƒì§€ (ìµœê·¼ {DEFAULT_RECENT_DAYS}ì¼ vs ê³¼ê±° {DEFAULT_BASELINE_DAYS}ì¼, zâ‰¥Â±{SURGE_Z_THRESHOLD})", expanded=True):
        surge_df = rate_change_flag(
            st.session_state["filtered_df"],
            recent_days=int(DEFAULT_RECENT_DAYS),
            baseline_days=int(DEFAULT_BASELINE_DAYS),
        )
        st.session_state["alerts_surge"] = surge_df
        if surge_df is not None and not surge_df.empty:
            st.write(f"ë¶„ì„ ëŒ€ìƒ ì¡°í•© ìˆ˜: **{len(surge_df):,}**")
            st.dataframe(surge_df.head(200), use_container_width=True)

            s1, s2, s3 = st.columns(3)
            with s1: st.metric("ìƒìŠ¹ ê²½ë³´", int((surge_df["flag"]=="ìƒìŠ¹").sum()))
            with s2: st.metric("í•˜ë½ ê°ì§€", int((surge_df["flag"]=="í•˜ë½").sum()))
            with s3: st.metric("ì •ìƒ", int((surge_df["flag"]=="ì •ìƒ").sum()))

            st.markdown("##### ì„ íƒ í•­ëª© ê·¸ë˜í”„")
            view_df = surge_df.head(200).copy()
            view_df["key"] = view_df["supplier_code"] + " | " + view_df["material_code"] + " | " + view_df["contam_type"]
            sel = st.selectbox("í•­ëª© ì„ íƒ (ê³µê¸‰ì‚¬ | ì›ë£Œ | ìœ í˜•)", options=view_df["key"].tolist())
            sel_row = view_df[view_df["key"]==sel].iloc[0]

            compare_df = pd.DataFrame({
                "ì§€í‘œ": ["ìµœê·¼ ì‹¤ì¸¡(x)", "ìµœê·¼ ê¸°ëŒ€(expected)", f"ê¸°ì¤€ì„  í•©({DEFAULT_BASELINE_DAYS}ì¼)"],
                "ê°’": [float(sel_row.get("x",0)), float(sel_row.get("expected_recent",0)), float(sel_row.get("base_count",0))]
            }).set_index("ì§€í‘œ")
            st.bar_chart(compare_df, use_container_width=True)
            st.caption("â€¢ ì‹¤ì¸¡(x): ìµœê·¼ ì°½ì˜ ì‹¤ì œ ê±´ìˆ˜  â€¢ ê¸°ëŒ€(expected): ê¸°ì¤€ì„ ì„ ë°”íƒ•ìœ¼ë¡œ ìµœê·¼ ì°½ì—ì„œ ê¸°ëŒ€ë˜ëŠ” ê±´ìˆ˜  â€¢ ê¸°ì¤€ì„  í•©: ê¸°ì¤€ì„  ê¸°ê°„ ì „ì²´ í•©ê³„")
        else:
            st.info("ìœ íš¨í•œ ê¸°ê°„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# â‘¢ ì•¡ì…˜ í…œí”Œë¦¿ (í™”ë©´ ì¶œë ¥ + ë³µì‚¬ + txt)
# -----------------------------
with tab3:
    st.subheader("ì•¡ì…˜ í…œí”Œë¦¿ ìƒì„±")

    surge_all = st.session_state.get("alerts_surge", pd.DataFrame())
    novel_view = st.session_state.get("alerts_novel", pd.DataFrame())

    if surge_all is None or surge_all.empty:
        st.info("ê²½ë³´ ë³´ë“œì—ì„œ ê²°ê³¼ê°€ ìƒì„±ëœ í›„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        # ì •ìƒ ì œì™¸ + |z| ë‚´ë¦¼ì°¨ìˆœ
        non_normal = surge_all[surge_all["flag"]!="ì •ìƒ"].copy()
        if non_normal.empty:
            st.info("ìƒìŠ¹/í•˜ë½ ê²½ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            non_normal["abs_z"] = non_normal["z"].abs()
            top_n = st.slider("ì•Œë¦¼ ìƒìœ„ N(|z| ê¸°ì¤€)", min_value=5, max_value=100, value=20, step=5)
            top_df = non_normal.sort_values("abs_z", ascending=False).head(top_n)

            today_str = datetime.now().strftime("%Y-%m-%d")
            intro = f"[ìë™ìƒì„±] ì´ë¬¼ ê¸‰ì¦/í•˜ë½Â·ì‹ ê·œ ìœ í˜• ëª¨ë‹ˆí„°ë§ ì•Œë¦¼ â€“ {today_str}\n"

            lines_out = []
            for _, r in top_df.iterrows():
                key = f"{r.get('supplier_code','')}-{r.get('material_code','')}-{r.get('contam_type','')}"
                lines_out.append(f"â€¢ {key}: ìµœê·¼={int(r.get('x',0))}ê±´, ê¸°ëŒ€={r.get('expected_recent',0):.1f}ê±´, z={r.get('z',0):.2f}, íŒì •={r.get('flag','')}")
            summary = "\n".join(lines_out[:200])

            novel_lines = []
            if novel_view is not None and not novel_view.empty:
                for _, r in novel_view.head(20).iterrows():
                    key = f"{r.get('supplier_code','')}-{r.get('material_code','')}"
                    novel_lines.append(f"â€¢ [ì‹ ê·œ] {key}ì—ì„œ '{r.get('contam_type','')}' ìµœì´ˆ ë°œìƒ @ {r.get('dt')}")
            novel_text = "\n".join(novel_lines)

            guidance = (
                "\n[ê¶Œê³  ì•¡ì…˜]\n"
                "- ê³µì • ì„ ë³„ê°•ë„ ìƒí–¥ ë° í•´ë‹¹ LOT ì¶”ê°€ê²€ì‚¬\n"
                "- ê³µê¸‰ì‚¬ ì›ì¸ì ê²€ ìš”ì²­(ì‚¬ì§„/ì¦ë¹™ ì²¨ë¶€)\n"
                "- (ì„ê³„ ì´ˆê³¼ ì‹œ) ì›ë£Œ LOT Hold ë° ê´€ë ¨ ì œí’ˆ LOT ì¶œê³ ì¤‘ì§€ ê²€í† \n"
                "- CAPA ë“±ë¡ ë° ì¬ë°œë°©ì§€ ì¶”ì "
            )

            email_text = intro + "\n[ê¸‰ì¦Â·í•˜ë½ ìƒìœ„ ìš”ì•½]\n" + summary + ("\n\n[ì‹ ê·œ ì´ë¬¼ ê°ì§€]\n" + novel_text if novel_text else "") + guidance

            st.markdown("#### ğŸ“£ ë°œì†¡/ê³µìœ ìš© ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°")
            st.text_area("ë³¸ë¬¸", value=email_text, height=300)

            # ë³µì‚¬ ë²„íŠ¼
            components.html(
                f"""
                <button onclick="navigator.clipboard.writeText({email_text!r});
                                 const s=this; s.innerText='ë³µì‚¬ë¨!'; setTimeout(()=>s.innerText='í´ë¦½ë³´ë“œë¡œ ë³µì‚¬',1200);"
                        style="padding:8px 14px; border-radius:8px; border:1px solid #ddd; cursor:pointer;">
                    í´ë¦½ë³´ë“œë¡œ ë³µì‚¬
                </button>
                """,
                height=60
            )
            st.download_button("ë³¸ë¬¸ .txt ë‹¤ìš´ë¡œë“œ", data=email_text.encode("utf-8-sig"), file_name="alert_message.txt")

# -----------------------------
# â‘£ ë‚´ë³´ë‚´ê¸° (CSV/XLSX)
# -----------------------------
with tab4:
    st.subheader("ê²°ê³¼ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°")

    f = st.session_state.get("filtered_df", pd.DataFrame())
    pv = st.session_state.get("pivot_df", None)
    nov = st.session_state.get("alerts_novel", pd.DataFrame())
    surge = st.session_state.get("alerts_surge", pd.DataFrame())

    if not f.empty:
        st.download_button("í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=f.to_csv(index=False).encode("utf-8-sig"), file_name="filtered_incidents.csv")
    else:
        st.info("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (íƒ­â‘ ì—ì„œ ì¡°ê±´ì„ ì¡°ì •í•˜ì„¸ìš”)")

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        if not f.empty:
            f.to_excel(writer, sheet_name="FilteredData", index=False)
            writer.sheets["FilteredData"].freeze_panes(1,0)
        if pv is not None:
            pv_out = pv.copy()
            if isinstance(pv_out, pd.Series):
                pv_out = pv_out.to_frame("value")
            if isinstance(pv_out.index, pd.MultiIndex):
                pv_out.index = [' | '.join(map(str, t)) for t in pv_out.index]
            if isinstance(pv_out.columns, pd.MultiIndex):
                pv_out.columns = [' | '.join(map(str, t)) for t in pv_out.columns]
            pv_out.to_excel(writer, sheet_name="Pivot", merge_cells=False)
            writer.sheets["Pivot"].freeze_panes(1,1)
        if nov is not None and not nov.empty:
            nov.to_excel(writer, sheet_name="NovelAlerts", index=False)
            writer.sheets["NovelAlerts"].freeze_panes(1,0)
        if surge is not None and not surge.empty:
            surge.to_excel(writer, sheet_name="SurgeAlerts", index=False)
            writer.sheets["SurgeAlerts"].freeze_panes(1,0)

    st.download_button("ì—‘ì…€ ë³´ê³ ì„œ(XLSX) ë‹¤ìš´ë¡œë“œ", data=output.getvalue(), file_name="ACE_report.xlsx")

st.caption("â€» ê³ ë„í™”: ë¶„ëª¨(ì„ ë³„ëŸ‰) ê¸°ë°˜ ì„ê³„ ê²½ë³´, LOTâ†”ì œí’ˆ íŠ¸ë ˆì´ìŠ¤, ìë™ ë©”ì¼/Teams ì „ì†¡(Graph API) ë“± í™•ì¥ ê°€ëŠ¥.")
