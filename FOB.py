# FOB.py (v0.3) â€” FOCast web app
# V5 schema + rate-based alerts + dependent filters + chart axis toggle + XLSX engine fallback

import io
from datetime import datetime, timedelta, date

import numpy as np
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components

# ì‹œê°í™”(ì¶• ì „í™˜/ë ˆì´ì–´ë§)ë¥¼ ìœ„í•´ Altair ì‚¬ìš©
import altair as alt

# -----------------------------
# ì „ì—­ ì„¤ì • ë° ìƒìˆ˜
# -----------------------------
st.set_page_config(page_title="FOCast - ì´ë¬¼ ë¶„ì„Â·ì•Œë¦¼", layout="wide", initial_sidebar_state="expanded")
APP_TITLE = "FOCast â€“ ì´ë¬¼ ë¶„ì„Â·ì•Œë¦¼ ì›¹ì•±"
SECRET_CODE = "cj123456"  # ì£¼ê¸°ì  ë³€ê²½ ì˜ˆì •

# V5 ìŠ¤í‚¤ë§ˆ (stage ì œê±°, material_type ì¶”ê°€)
REQUIRED_COLUMNS = [
    "dt","plant","line",
    "material_type",          # NEW in V5
    "material_code","material_name",
    "supplier_code","supplier_name",
    "contam_type","color_tags",
    "count","unit","lot_no","severity",
    "photo_url","notes",
    "origin","imported",
    "selection_amount_kg",
    "ì´ë¬¼ìˆ˜ì¤€","ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€","ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"
]

DEFAULT_RECENT_DAYS = 7
DEFAULT_BASELINE_DAYS = 180
SURGE_Z_THRESHOLD = 3.0  # z >= 3 ìƒìŠ¹, z <= -3 í•˜ë½

# -----------------------------
# ì¸ì¦
# -----------------------------
def auth_gate():
    st.markdown("### ğŸ” ë³´ì•ˆì½”ë“œ ì…ë ¥")
    with st.form("auth_form", clear_on_submit=False):
        code = st.text_input("ë³´ì•ˆì½”ë“œ", type="password", help="ì ‘ì† ë³´ì•ˆì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        ok = st.form_submit_button("ì ‘ì†")
        if ok:
            if code == SECRET_CODE:
                st.session_state["_authed"] = True
                st.success("ì ‘ì† í—ˆìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.session_state["_authed"] = False
                st.error("ë³´ì•ˆì½”ë“œê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

if "_authed" not in st.session_state:
    st.session_state["_authed"] = False

st.title(APP_TITLE)

if not st.session_state["_authed"]:
    auth_gate()
    st.stop()

# -----------------------------
# ìœ í‹¸ & ì „ì²˜ë¦¬
# -----------------------------
@st.cache_data(show_spinner=False)
def load_file(uploaded_file, sheet_name: str | None = None) -> pd.DataFrame:
    """CSV/Excel íŒŒì¼ ë¡œë“œ (ì—‘ì…€ì€ ê¸°ë³¸ì ìœ¼ë¡œ 'ì²« ë²ˆì§¸ ì‹œíŠ¸' ë˜ëŠ” 'Incidents' ì‹œíŠ¸ ì„ íƒ)"""
    name = uploaded_file.name.lower()

    # CSV ì²˜ë¦¬: ì¸ì½”ë”© ìë™ í´ë°±
    if name.endswith(".csv"):
        try:
            return pd.read_csv(uploaded_file)  # ê¸°ë³¸ UTF-8
        except UnicodeDecodeError:
            uploaded_file.seek(0)
            return pd.read_csv(uploaded_file, encoding="cp949")

    # Excel ì²˜ë¦¬
    if name.endswith((".xlsx", ".xls")):
        import openpyxl  # ensure installed
        # 1) ì‚¬ìš©ìê°€ ì‹œíŠ¸ëª…ì„ ì§€ì •í•œ ê²½ìš°
        if sheet_name and str(sheet_name).strip():
            return pd.read_excel(uploaded_file, sheet_name=str(sheet_name).strip(), engine="openpyxl")

        # 2) ë¯¸ì§€ì • ì‹œ â†’ ì²« ì‹œíŠ¸ ë˜ëŠ” 'Incidents' ìš°ì„  ì„ íƒ
        xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
        preferred = [s for s in xls.sheet_names if s.lower() in ("incidents", "data", "sheet1")]
        pick = preferred[0] if preferred else xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=pick)
        # ì„ íƒëœ ì‹œíŠ¸ëª…ì„ í™”ë©´ì— í‘œì‹œ(ë””ë²„ê¹…/ê°€ì´ë“œìš©)
        st.caption(f"ì—‘ì…€ ì‹œíŠ¸ ìë™ ì„ íƒ: **{pick}** (íŒŒì¼ ë‚´ ì‹œíŠ¸: {', '.join(xls.sheet_names)})")
        return df

    raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” Excel(.xlsx/.xls)ë§Œ ì—…ë¡œë“œí•˜ì„¸ìš”.")

def ensure_columns(df: pd.DataFrame) -> pd.DataFrame:
    """í•„ìˆ˜ ì»¬ëŸ¼/íƒ€ì… ë³´ì • (V5)"""
    for col in REQUIRED_COLUMNS:
        if col not in df.columns:
            df[col] = np.nan

    # ë‚ ì§œ íŒŒì‹±: V5ëŠ” ë‚ ì§œê¹Œì§€ë§Œ ì¡´ì¬
    try:
        df["dt"] = pd.to_datetime(df["dt"]).dt.date
    except Exception:
        df["dt"] = pd.to_datetime(df["dt"], errors="coerce").dt.date

    # ìˆ«ìí˜•
    for c in ["count", "selection_amount_kg", "ì´ë¬¼ìˆ˜ì¤€", "ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€", "ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    df["count"] = df["count"].fillna(0).astype(int)
    df["selection_amount_kg"] = df["selection_amount_kg"].fillna(0).astype(int)
    for c in ["ì´ë¬¼ìˆ˜ì¤€","ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€","ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€"]:
        df[c] = df[c].fillna(0.0).astype(float)

    # ë¬¸ìì—´í˜•
    str_cols = [
        "plant","line","material_type","material_code","material_name",
        "supplier_code","supplier_name","contam_type","color_tags",
        "unit","lot_no","severity","photo_url","notes","origin","imported"
    ]
    for c in str_cols:
        df[c] = df[c].fillna("").astype(str)

    return df

def split_tags(s: str):
    if not isinstance(s, str):
        return []
    return [t.strip() for t in s.split(";") if t.strip()]

def tag_filter_mask(series_tags: pd.Series, selected_tags, mode="ANY"):
    if not selected_tags:
        return pd.Series([True]*len(series_tags), index=series_tags.index)
    row_tags = series_tags.apply(split_tags)
    if mode == "ALL":
        mask = row_tags.apply(lambda lst: all(t in lst for t in selected_tags))
    else:
        mask = row_tags.apply(lambda lst: any(t in lst for t in selected_tags))
    return mask

def flatten_index(idx):
    if hasattr(idx, "names") and isinstance(idx, pd.MultiIndex):
        return [" | ".join(map(str, tup)) for tup in idx.to_list()]
    return [str(x) for x in idx]

# -----------------------------
# ë¶„ì„ í•¨ìˆ˜ (V5: rate ê¸°ë°˜)
# -----------------------------
def detect_novel_types(df: pd.DataFrame,
                       key_cols=("supplier_code","material_code"),
                       type_col="contam_type",
                       time_col="dt") -> pd.DataFrame:
    f = df[[*key_cols, type_col, time_col]].copy()
    f = f.sort_values(time_col)
    seen, flags = {}, []
    for _, row in f.iterrows():
        key = tuple(row[c] for c in key_cols)
        t = row[type_col]
        if key not in seen:
            seen[key] = set()
        novel = t not in seen[key]
        flags.append(novel)
        seen[key].add(t)
    f["is_novel_type"] = flags
    return f

def rate_change_flag_v5(df: pd.DataFrame,
                        key_cols=("supplier_code","material_code","contam_type"),
                        count_col="count",
                        exposure_col="selection_amount_kg",
                        time_col="dt",
                        recent_days=DEFAULT_RECENT_DAYS,
                        baseline_days=DEFAULT_BASELINE_DAYS) -> pd.DataFrame:
    """ì´ë¬¼ìˆ˜ì¤€(=count/exposure) ê¸°ë°˜ ê¸‰ì¦/í•˜ë½ íƒì§€.
       z = (r_recent - r_base) / sqrt(r_base / recent_exposure)
       (Poisson with exposure ê·¼ì‚¬, small-sample ì•ˆì •í™” í¬í•¨)
    """
    g = df[[*key_cols, count_col, exposure_col, time_col]].copy()
    g["date"] = g[time_col]
    if g["date"].isna().all():
        return pd.DataFrame()

    today = max([d for d in g["date"] if pd.notna(d)], default=None)
    if pd.isna(today) or today is None:
        return pd.DataFrame()

    recent_start = today - timedelta(days=recent_days-1)
    base_end = recent_start - timedelta(days=1)
    base_start = base_end - timedelta(days=baseline_days-1)

    recent = g[(g["date"]>=recent_start) & (g["date"]<=today)]
    base   = g[(g["date"]>=base_start) & (g["date"]<=base_end)]

    if recent.empty and base.empty:
        return pd.DataFrame()

    # ì§‘ê³„: ë¶„ì/ë¶„ëª¨ ë”°ë¡œ í•©ì‚°
    r = recent.groupby(list(key_cols))[[count_col, exposure_col]].sum().rename(columns={
        count_col: "x_cnt", exposure_col: "x_exp"
    }).reset_index()
    b = base.groupby(list(key_cols))[[count_col, exposure_col]].sum().rename(columns={
        count_col: "b_cnt", exposure_col: "b_exp"
    }).reset_index()

    merged = pd.merge(r, b, on=list(key_cols), how="outer").fillna(0)

    # rate ê³„ì‚°
    merged["x_rate"] = np.where(merged["x_exp"]>0, merged["x_cnt"] / merged["x_exp"], 0.0)
    merged["b_rate"] = np.where(merged["b_exp"]>0, merged["b_cnt"] / merged["b_exp"], 0.0)

    # ìµœê·¼ ê¸°ëŒ€ rate = b_rate (ê¸°ì¤€ì„ )
    merged["expected_recent_rate"] = merged["b_rate"]

    # z-score (ì•ˆì •í™”: base_rate ìµœì†Œê°’ ë°”ë‹¥ì¹˜)
    eps = 1e-9
    denom = np.sqrt((merged["b_rate"] + eps) / (merged["x_exp"] + eps))
    merged["z"] = (merged["x_rate"] - merged["b_rate"]) / denom.replace(0, np.nan)
    merged["z"] = merged["z"].replace([np.inf, -np.inf], 0).fillna(0)

    merged["flag"] = np.select(
        [merged["z"] >= SURGE_Z_THRESHOLD, merged["z"] <= -SURGE_Z_THRESHOLD],
        ["ìƒìŠ¹","í•˜ë½"], default="ì •ìƒ"
    )

    # ì°¸ê³ ìš© ì»¬ëŸ¼(ê¸°ì¡´í‘œí˜„ ìœ ì§€)
    merged["x"] = merged["x_cnt"]
    merged["base_count"] = merged["b_cnt"]
    merged["expected_recent"] = merged["expected_recent_rate"] * merged["x_exp"]

    # ì •ë ¬
    merged = merged.sort_values("z", ascending=False)
    return merged

# -----------------------------
# ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ (êµì²´)
# -----------------------------
with st.sidebar:
    st.header("â‘  ë°ì´í„° ì—…ë¡œë“œ")
    uploaded = st.file_uploader("ì—‘ì…€/CSV ì—…ë¡œë“œ", type=["csv","xlsx","xls"])

    # ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•´ ê°•ì œ ì§€ì •í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ì…ë ¥(ì˜µì…˜)
    sheet_name_input = st.text_input("ì—‘ì…€ ì‹œíŠ¸ëª…(ì˜µì…˜)", value="")

    # ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—‘ì…€ì´ë¼ë©´: ì‹œíŠ¸ ëª©ë¡ ì•ˆë‚´ + ì„ íƒ ë°•ìŠ¤ ì œê³µ
    sheet_choice = None
    if uploaded and uploaded.name.lower().endswith((".xlsx", ".xls")):
        try:
            import openpyxl  # ensure installed
            # ì—…ë¡œë” ìŠ¤íŠ¸ë¦¼ì„ í•œë²ˆ ì½ìœ¼ë©´ í¬ì¸í„°ê°€ ì´ë™í•˜ë¯€ë¡œ, ì‚¬ìš© í›„ ë°˜ë“œì‹œ seek(0) ë³µêµ¬
            xls = pd.ExcelFile(uploaded, engine="openpyxl")
            # ëª©ë¡ ì•ˆë‚´
            st.caption("ì´ íŒŒì¼ì˜ ì‹œíŠ¸: " + ", ".join(xls.sheet_names))

            # ì¶”ì²œ ê¸°ë³¸ ì‹œíŠ¸(ìˆìœ¼ë©´ incidents/data/sheet1 â†’ ì—†ìœ¼ë©´ ì²« ì‹œíŠ¸)
            preferred = [s for s in xls.sheet_names if s.lower() in ("incidents", "data", "sheet1")]
            default_sheet = preferred[0] if preferred else xls.sheet_names[0]
            default_idx = xls.sheet_names.index(default_sheet)

            # ì„ íƒ UI
            sheet_choice = st.selectbox("ì‹œíŠ¸ ì„ íƒ(ìë™ ê°ì§€)", options=xls.sheet_names, index=default_idx)

        except Exception as e:
            st.warning(f"ì‹œíŠ¸ ëª©ë¡ì„ ì½ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        finally:
            # ì´í›„ ì‹¤ì œ ë¡œë”©ì„ ìœ„í•´ íŒŒì¼ í¬ì¸í„° ë³µêµ¬
            try:
                uploaded.seek(0)
            except Exception:
                pass

    st.header("â‘¡ íƒœê·¸ ë§¤ì¹­")
    tag_mode = st.radio("íƒœê·¸ ëª¨ë“œ", ["ANY(í•˜ë‚˜ë¼ë„ ì¼ì¹˜)","ALL(ëª¨ë‘ í¬í•¨)"], index=0)
    st.caption("ğŸ’¡ ì—…ë¡œë“œ í›„ ìƒë‹¨ íƒ­ì—ì„œ í”¼ë²—/ê²½ë³´/ì•¡ì…˜/ë‚´ë³´ë‚´ê¸°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

if uploaded is None:
    st.info("ì™¼ìª½ì—ì„œ CSV ë˜ëŠ” ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (V5 ìŠ¤í‚¤ë§ˆ ê¶Œì¥)")
    st.stop()

# í…ìŠ¤íŠ¸ ì…ë ¥ì´ ìš°ì„ , ì—†ìœ¼ë©´ ì„ íƒë°•ìŠ¤ ê°’ ì‚¬ìš©
chosen_sheet = sheet_name_input.strip() or sheet_choice

try:
    df_raw = load_file(uploaded, sheet_name=chosen_sheet if chosen_sheet else None)
except Exception as e:
    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
    st.stop()


df = ensure_columns(df_raw)

min_dt = pd.to_datetime(df["dt"]).min()
max_dt = pd.to_datetime(df["dt"]).max()

# -----------------------------
# ìƒë‹¨ KPI
# -----------------------------
k1,k2,k3,k4 = st.columns(4)
with k1:
    st.metric("ì´ ê±´ìˆ˜", f"{len(df):,}")
with k2:
    st.metric("ê³ ìœ  ì›ë£Œì½”ë“œ", df["material_code"].nunique())
with k3:
    st.metric("ê³µê¸‰ì‚¬ ìˆ˜", df["supplier_code"].nunique())
with k4:
    st.metric("ê¸°ê°„ ë²”ìœ„", f"{min_dt} ~ {max_dt}" if pd.notna(min_dt) else "-")

# íƒ­ ìƒíƒœ
st.session_state.setdefault("pivot_df", None)
st.session_state.setdefault("alerts_novel", None)
st.session_state.setdefault("alerts_surge", None)
st.session_state.setdefault("filtered_df", None)

# -----------------------------
# íƒ­ êµ¬ì„±
# -----------------------------
tab1, tab2, tab3, tab4 = st.tabs([
    "â‘  í”¼ë²—/í•„í„° ê²€ìƒ‰", "â‘¡ ê²½ë³´ ë³´ë“œ", "â‘¢ ì•¡ì…˜ í…œí”Œë¦¿", "â‘£ ë‚´ë³´ë‚´ê¸°"
])

# -----------------------------
# â‘  í”¼ë²—/í•„í„° ê²€ìƒ‰
# -----------------------------
with tab1:
    st.subheader("í”¼ë²—/í•„í„° ê²€ìƒ‰")

    # ---- í•„í„° (4ê°œì”© ë°°ì¹˜) ----
    today_d = date.today()
    default_start = today_d - timedelta(days=365)
    default_end = today_d

    # material_typeâ†’ material_name/code ì˜ì¡´ì„ ìœ„í•œ ë§µ
    map_type_to_materials = (
        df.groupby("material_type")[["material_code","material_name"]]
          .apply(lambda g: g.drop_duplicates().to_dict("records"))
          .to_dict()
    )

    # 1í–‰
    c1,c2,c3,c4 = st.columns(4)
    with c1:
        plants = st.multiselect("ê³µì¥(plant)", sorted([p for p in df["plant"].unique() if p!=""]))
    with c2:
        lines = st.multiselect("ë¼ì¸(line)", sorted([p for p in df["line"].unique() if p!=""]))
    with c3:
        suppliers = st.multiselect("ê³µê¸‰ì‚¬ ì½”ë“œ(supplier_code)", sorted([p for p in df["supplier_code"].unique() if p!=""]), key="supplier_select")
    with c4:
        supplier_names = st.multiselect("ê³µê¸‰ì‚¬ëª…(supplier_name)", sorted([p for p in df["supplier_name"].unique() if p!=""]))

    # 2í–‰
    c5,c6,c7,c8 = st.columns(4)
    with c5:
        mat_types = st.multiselect("ì›ë£ŒëŒ€ë¶„ë¥˜(material_type)", sorted([p for p in df["material_type"].unique() if p!=""]), key="mat_type_select")
    with c6:
        # material_type & supplier êµì§‘í•©ìœ¼ë¡œ material í›„ë³´ ì œí•œ
        if mat_types:
            subset = df[df["material_type"].isin(mat_types)]
        else:
            subset = df
        if suppliers or supplier_names:
            subset = subset[
                subset["supplier_code"].isin(suppliers) if suppliers else subset.index.isin(subset.index)
            ]
            if supplier_names:
                subset = subset[subset["supplier_name"].isin(supplier_names)]
        mat_name_opts = sorted(subset["material_name"].dropna().unique())
        material_names = st.multiselect("ì›ë£Œëª…(material_name)", mat_name_opts, key="material_name_select")
    with c7:
        # material_nameì„ ì¬ì°¨ ë°˜ì˜í•´ code í›„ë³´ ì œí•œ
        subset2 = subset[subset["material_name"].isin(material_names)] if material_names else subset
        mat_code_opts = sorted(subset2["material_code"].dropna().unique())
        materials = st.multiselect("ì›ë£Œì½”ë“œ(material_code)", mat_code_opts, key="material_code_select")
    with c8:
        fo_types = st.multiselect("ì´ë¬¼ ìœ í˜•(contam_type)", sorted([p for p in df["contam_type"].unique() if p!=""]))

    # 3í–‰
    c9,c10,c11,c12 = st.columns(4)
    with c9:
        severities = st.multiselect("ì¤‘ëŒ€/ì¼ë°˜(severity)", ["ì¤‘ëŒ€","ì¼ë°˜"])
    with c10:
        origins = st.multiselect("ì›ì‚°ì§€(origin)", sorted([p for p in df["origin"].unique() if p!=""]))
    with c11:
        imported = st.multiselect("ìˆ˜ì…ì—¬ë¶€(imported)", sorted([p for p in df["imported"].unique() if p!=""]))
    with c12:
        unique_tags = sorted({t for row in df["color_tags"] for t in split_tags(row)})
        tags = st.multiselect("íƒœê·¸(color_tags)", unique_tags)

    # 4í–‰ (ê¸°ê°„)
    c13,c14,c15,c16 = st.columns(4)
    with c13:
        date_from = st.date_input("ì‹œì‘ì¼", value=default_start)
    with c14:
        date_to = st.date_input("ì¢…ë£Œì¼", value=default_end)
    with c15:
        st.write("")  # ìë¦¬ë§ì¶¤
    with c16:
        st.write("")  # ìë¦¬ë§ì¶¤

    # ---- í•„í„° ì ìš© ----
    f = df.copy()
    if plants:         f = f[f["plant"].isin(plants)]
    if lines:          f = f[f["line"].isin(lines)]
    if suppliers:      f = f[f["supplier_code"].isin(suppliers)]
    if supplier_names: f = f[f["supplier_name"].isin(supplier_names)]
    if mat_types:      f = f[f["material_type"].isin(mat_types)]
    if material_names: f = f[f["material_name"].isin(material_names)]
    if materials:      f = f[f["material_code"].isin(materials)]
    if fo_types:       f = f[f["contam_type"].isin(fo_types)]
    if severities:     f = f[f["severity"].isin(severities)]
    if origins:        f = f[f["origin"].isin(origins)]
    if imported:       f = f[f["imported"].isin(imported)]
    # ë‚ ì§œ
    f = f[(pd.to_datetime(f["dt"]) >= pd.to_datetime(date_from)) & (pd.to_datetime(f["dt"]) <= pd.to_datetime(date_to))]
    # íƒœê·¸
    mode = "ALL" if tag_mode.startswith("ALL") else "ANY"
    f = f[tag_filter_mask(f["color_tags"], selected_tags=tags, mode=mode)]

    st.session_state["filtered_df"] = f

    st.write(f"í•„í„° ê²°ê³¼: **{len(f):,}ê±´**")
    st.dataframe(f.head(200), use_container_width=True)

    # ---- í”¼ë²— ----
    st.markdown("#### í”¼ë²— í…Œì´ë¸”")
    pv_c1, pv_c2, pv_c3, pv_c4 = st.columns([1.4,1,1,1])
    with pv_c1:
        row_opts = ["plant","line","supplier_code","supplier_name","material_type","material_code","material_name","contam_type","severity","origin","imported"]
        rows = st.multiselect("í–‰(ë‹¤ì¤‘ ì„ íƒ)", row_opts)
    with pv_c2:
        col_opts = ["plant","line","supplier_code","material_type","material_code","contam_type","severity","origin","imported"]
        cols = st.multiselect("ì—´(ì„ íƒ)", col_opts)
    with pv_c3:
        agg_metric = st.selectbox("ì§€í‘œ", [
            "count í•©ê³„ (ê±´ìˆ˜)","ë ˆì½”ë“œ ìˆ˜",
            "ì´ë¬¼ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)",
            "ì¤‘ëŒ€ì´ë¬¼ ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)",
            "ì¼ë°˜ì´ë¬¼ ìˆ˜ì¤€ (ë¶„ìí•©/ì„ ë³„ëŸ‰í•©)"
        ])
    with pv_c4:
        chart_type = st.selectbox("ì°¨íŠ¸ ìœ í˜•", ["ë§‰ëŒ€(bar)","ì„ (line)","ì˜ì—­(area)"])

    # (íƒ­â‘  í”¼ë²—/í•„í„° ë‚´ë¶€) ì¶• ì „í™˜ í† ê¸€ ë¼ì¸ ëŒ€ì²´
    axis_toggle = st.toggle("ì°¨íŠ¸ ê°€ë¡œ/ì„¸ë¡œì¶• ì „í™˜ (ê¸°ë³¸=ê°€ë¡œí˜•)", value=True)  # False=ì„¸ë¡œí˜•, True=ê°€ë¡œí˜• ê¸°ë³¸


    def pivot_rates(frame, rows, cols, which="all"):
        """which: 'all'|'sev'|'norm' -> (sum count)/sum selection_amount_kg"""
        grp = rows + (cols if cols else [])
        denom = frame.groupby(grp)["selection_amount_kg"].sum()
        if which == "all":
            num = frame.groupby(grp)["count"].sum()
        elif which == "sev":
            num = frame.assign(_num=np.where(frame["severity"]=="ì¤‘ëŒ€", frame["count"], 0)).groupby(grp)["_num"].sum()
        else:  # 'norm'
            num = frame.assign(_num=np.where(frame["severity"]=="ì¼ë°˜", frame["count"], 0)).groupby(grp)["_num"].sum()
        rate = (num / denom.replace(0, np.nan)).fillna(0.0)
        if cols:
            return rate.unstack(cols).fillna(0.0)
        else:
            return rate.to_frame("value")

    pt = None
    if rows:
        g = f.copy()
        if agg_metric.startswith("count"):
            if agg_metric.startswith("count í•©ê³„"):
                values = "count"; aggfunc = "sum"
            else:
                g["__one__"] = 1; values = "__one__"; aggfunc = "sum"
            if cols:
                pt = pd.pivot_table(g, index=rows, columns=cols, values=values, aggfunc=aggfunc, fill_value=0)
            else:
                pt = g.groupby(rows)[values].sum().to_frame("value")
        else:
            if "ì´ë¬¼ìˆ˜ì¤€" in agg_metric:
                pt = pivot_rates(g, rows, cols, which="all")
            elif "ì¤‘ëŒ€ì´ë¬¼" in agg_metric:
                pt = pivot_rates(g, rows, cols, which="sev")
            else:
                pt = pivot_rates(g, rows, cols, which="norm")

        st.session_state["pivot_df"] = pt
        st.dataframe(pt, use_container_width=True)

        # ---- í”¼ë²— ì°¨íŠ¸ (Altair + ì¶• ì „í™˜) ----
        st.markdown("##### í”¼ë²— ì°¨íŠ¸")
        chart_df = pt.copy()
        if isinstance(chart_df, pd.Series):
            chart_df = chart_df.to_frame("value")
        if isinstance(chart_df.index, pd.MultiIndex):
            chart_df.index = flatten_index(chart_df.index)
        if isinstance(chart_df.columns, pd.MultiIndex):
            chart_df.columns = flatten_index(chart_df.columns)
        chart_df = chart_df.reset_index().rename(columns={"index":"row"})
        # í­ ì œí•œ
        if chart_df.shape[0] > 2000:
            st.caption("âš ï¸ ì°¨íŠ¸ ì„±ëŠ¥ì„ ìœ„í•´ ìƒìœ„ 2000 ì…€ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
            chart_df = chart_df.head(2000)

        # wide->long
        chart_long = chart_df.melt(id_vars=chart_df.columns[0], var_name="col", value_name="val")
        row_field = chart_df.columns[0]

        base = alt.Chart(chart_long).transform_filter(alt.datum.val != None)
        if axis_toggle:
            enc = base.mark_bar().encode(
                x=alt.X("val:Q", title="ê°’"),
                y=alt.Y(f"{row_field}:N", title="í–‰"),
                color=alt.Color("col:N", title="ì—´", legend=alt.Legend(columns=2))
            )
        else:
            enc = base.mark_bar().encode(
                x=alt.X(f"{row_field}:N", title="í–‰"),
                y=alt.Y("val:Q", title="ê°’"),
                color=alt.Color("col:N", title="ì—´", legend=alt.Legend(columns=2))
            )

        if chart_type.startswith("ì„ "):
            enc = enc.mark_line(point=True)
        elif chart_type.startswith("ì˜ì—­"):
            enc = enc.mark_area(opacity=0.6)

        st.altair_chart(enc.properties(height=420), use_container_width=True)
    else:
        st.info("í–‰ ì°¨ì›ì„ 1ê°œ ì´ìƒ ì„ íƒí•˜ë©´ í”¼ë²—ì´ ìƒì„±ë©ë‹ˆë‹¤.")

with tab2:
    st.subheader("ì‹ ê·œ ì´ë¬¼ / ê¸‰ì¦ ê²½ë³´ ë³´ë“œ (ì´ë¬¼ìˆ˜ì¤€ ê¸°ë°˜)")

    # -----------------------------
    # ê³µí†µ: ì»¬ëŸ¼ ì •ê·œí™” + íƒ€ì… ë³´ì •
    # -----------------------------
    def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        base = {c: c.strip().lower() for c in df.columns}
        df.rename(columns=base, inplace=True)
        # ë™ì˜ì–´ ë§¤í•‘
        mapping = {
            "date": "dt", "datetime": "dt", "time": "dt",
            "factory": "plant", "site": "plant", "plantname": "plant",
            "linename": "line", "line_id": "line",
            "materialtype": "material_type", "mat_type": "material_type",
            "material": "material_code", "material_cd": "material_code", "item_code": "material_code", "sku": "material_code",
            "supplier": "supplier_code", "vendor": "supplier_code", "vendor_code": "supplier_code",
            "contam": "contam_type", "defect_type": "contam_type", "foreign_matter_type": "contam_type",
            "qty_kg": "selection_amount_kg", "amount_kg": "selection_amount_kg", "selection_kg": "selection_amount_kg",
            "counts": "count", "count_num": "count",
        }
        for src, dst in mapping.items():
            if src in df.columns and dst not in df.columns:
                df.rename(columns={src: dst}, inplace=True)
        # íƒ€ì…
        if "dt" in df.columns:
            df["dt"] = pd.to_datetime(df["dt"]).dt.date
        df["count"] = pd.to_numeric(df.get("count", 0), errors="coerce").fillna(0)
        df["selection_amount_kg"] = pd.to_numeric(df.get("selection_amount_kg", 0), errors="coerce").fillna(0)
        # í‚¤ ëˆ„ë½ ë°©ì§€ìš© ë¹ˆ ì»¬ëŸ¼
        for k in ["plant","line","material_type","material_code","supplier_code","contam_type"]:
            if k not in df.columns:
                df[k] = ""
        return df

    fdf = normalize_columns(st.session_state["filtered_df"])
    if fdf.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # -----------------------------
    # íŒŒë¼ë¯¸í„°/ê¸°ê°„
    # -----------------------------
    TODAY = fdf["dt"].max()
    RECENT_DAYS = int(DEFAULT_RECENT_DAYS)
    BASE_DAYS   = int(DEFAULT_BASELINE_DAYS)
    SURGE_Z     = float(SURGE_Z_THRESHOLD)
    EPS         = 1e-9

    recent_start  = TODAY - timedelta(days=RECENT_DAYS - 1)
    baseline_end  = recent_start - timedelta(days=1)
    baseline_start= baseline_end - timedelta(days=BASE_DAYS - 1)

    KEY7 = ["plant","line","material_type","material_code","supplier_code","contam_type"]

    # -----------------------------
    # 1) ê¸‰ì¦/í•˜ë½ (rate ê¸°ë°˜ z-ì ìˆ˜, í‚¤=7ê°œ)
    # -----------------------------
    def rate_change_flag_v5_full(df: pd.DataFrame,
                                 recent_days: int,
                                 baseline_days: int) -> pd.DataFrame:
        df = df.copy()

        # ìœˆë„ìš° ë¶„í• 
        mask_recent   = (df["dt"] >= recent_start) & (df["dt"] <= TODAY)
        mask_baseline = (df["dt"] >= baseline_start) & (df["dt"] <= baseline_end)

        # ì¼ì¼ í•©ì‚° (ë™ì¼ 7í‚¤ + dt ê¸°ì¤€ìœ¼ë¡œ ë¶„ì/ë¶„ëª¨ í•©)
        grp_cols = KEY7 + ["dt"]

        recent_daily = (
            df.loc[mask_recent, grp_cols + ["count","selection_amount_kg"]]
              .groupby(grp_cols, as_index=False)[["count","selection_amount_kg"]].sum()
        )
        base_daily = (
            df.loc[mask_baseline, grp_cols + ["count","selection_amount_kg"]]
              .groupby(grp_cols, as_index=False)[["count","selection_amount_kg"]].sum()
        )

        # ìµœê·¼/ê¸°ì¤€ ê¸°ê°„ í•©ê³„ (í‚¤=7ê°œ)
        key7_only = KEY7.copy()
        recent_sum = (
            recent_daily.groupby(key7_only, as_index=False)
                        .agg(x_cnt=("count","sum"), x_den=("selection_amount_kg","sum"))
        )
        base_sum = (
            base_daily.groupby(key7_only, as_index=False)
                      .agg(b_cnt=("count","sum"), b_den=("selection_amount_kg","sum"))
        )

        # ê²°í•©
        merged = recent_sum.merge(base_sum, on=key7_only, how="outer").fillna(0)

        # rate ê³„ì‚°
        merged["x_rate"] = np.where(merged["x_den"] > 0, merged["x_cnt"] / merged["x_den"], 0.0)
        merged["b_rate"] = np.where(merged["b_den"] > 0, merged["b_cnt"] / merged["b_den"], 0.0)

        # ê¸°ëŒ€ê°’ E = baseline_rate * recent_den
        merged["x_exp"] = merged["b_rate"] * merged["x_den"]

        # z-score (í¬ì•„ì†¡ ê·¼ì‚¬)
        merged["z"] = np.where(merged["x_exp"] > 0,
                               (merged["x_cnt"] - merged["x_exp"]) / np.sqrt(merged["x_exp"] + EPS),
                               0.0)

        merged["expected_recent_rate"] = np.where(merged["x_den"] > 0,
                                                  merged["x_exp"] / merged["x_den"], 0.0)

        merged["flag"] = np.select(
            [merged["z"] >= SURGE_Z, merged["z"] <= -SURGE_Z],
            ["ìƒìŠ¹","í•˜ë½"], default="ì •ìƒ"
        )

        # í‘œì‹œ ìˆœì„œ/ì»¬ëŸ¼ ì •ë¦¬
        cols = key7_only + ["x_cnt","x_den","x_rate","b_cnt","b_den","b_rate","expected_recent_rate","z","flag"]
        return merged[cols].sort_values("z", ascending=False)

    with st.expander(f"ê¸‰ì¦/í•˜ë½ íƒì§€ (ìµœê·¼ {RECENT_DAYS}ì¼ vs ê³¼ê±° {BASE_DAYS}ì¼, zâ‰¥Â±{SURGE_Z})", expanded=True):
        surge_df = rate_change_flag_v5_full(fdf, RECENT_DAYS, BASE_DAYS)
        st.session_state["alerts_surge"] = surge_df
        if surge_df is not None and not surge_df.empty:
            st.write(f"ë¶„ì„ ëŒ€ìƒ ì¡°í•© ìˆ˜: **{len(surge_df):,}**")
            st.dataframe(
                surge_df[KEY7 + ["x_cnt","x_den","x_rate","b_cnt","b_den","b_rate","expected_recent_rate","z","flag"]].head(200),
                use_container_width=True
            )
            s1, s2, s3 = st.columns(3)
            with s1: st.metric("ìƒìŠ¹ ê²½ë³´", int((surge_df["flag"]=="ìƒìŠ¹").sum()))
            with s2: st.metric("í•˜ë½ ê°ì§€", int((surge_df["flag"]=="í•˜ë½").sum()))
            with s3: st.metric("ì •ìƒ", int((surge_df["flag"]=="ì •ìƒ").sum()))
        else:
            st.info("ê¸‰ì¦/í•˜ë½ ë¶„ì„ ëŒ€ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ----- ì—¬ê¸°ë¶€í„° êµì²´: ì„ íƒ í•­ëª© ê·¸ë˜í”„ (ìµœê·¼ 180ì¼ 'ì´ë¬¼ìˆ˜ì¤€' ì‹œê³„ì—´ + SPC) -----
st.markdown("##### ì„ íƒ í•­ëª© ê·¸ë˜í”„ (ìµœê·¼ 180ì¼ ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€ + b/expected/x rate ì„ )")

if surge_df is None or surge_df.empty:
    st.info("í‘œì‹œí•  ì¡°í•©ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ì„ íƒ ë¼ë²¨ êµ¬ì„± (plant | line | material_type | supplier | material | contam)
def as_str(v): return "" if pd.isna(v) else str(v)
view_df = surge_df.head(1000).copy()
view_df["key"] = (
    view_df["plant"].map(as_str) + " | " +
    view_df["line"].map(as_str) + " | " +
    view_df["material_type"].map(as_str) + " | " +
    view_df["supplier_code"].map(as_str) + " | " +
    view_df["material_code"].map(as_str) + " | " +
    view_df["contam_type"].map(as_str)
)

sel = st.selectbox("í•­ëª© ì„ íƒ (plant | line | material_type | supplier | material | contam)",
                   options=view_df["key"].tolist())
srow = view_df[view_df["key"] == sel].iloc[0]

# ì¼ì ë²”ìœ„
base_start = TODAY - timedelta(days=BASE_DAYS - 1)

# ë™ì¼ 7í‚¤ + ë‚ ì§œ ë²”ìœ„ ë§ˆìŠ¤í¬
mask = (
    (fdf["dt"] >= base_start) & (fdf["dt"] <= TODAY) &
    (fdf["plant"]         == srow["plant"]) &
    (fdf["line"]          == srow["line"]) &
    (fdf["material_type"] == srow["material_type"]) &
    (fdf["material_code"] == srow["material_code"]) &
    (fdf["supplier_code"] == srow["supplier_code"]) &
    (fdf["contam_type"]   == srow["contam_type"])
)
ts = fdf.loc[mask, ["dt","count","selection_amount_kg"]].copy()

# ìº˜ë¦°ë”(ë¹ ì§„ ë‚ ì§œ 0 ì±„ì›€)
calendar = pd.DataFrame({"dt": [base_start + timedelta(days=i) for i in range(BASE_DAYS)]})
daily = (
    ts.groupby("dt", as_index=False)[["count","selection_amount_kg"]].sum()
      .merge(calendar, on="dt", how="right")
      .fillna({"count":0, "selection_amount_kg":0})
      .sort_values("dt")
)
daily["has_selection"] = daily["selection_amount_kg"] > 0  # (1) ì„ ë³„ æœ‰/ç„¡ í”Œë˜ê·¸
daily["daily_rate"] = np.where(daily["selection_amount_kg"]>0,
                               daily["count"]/daily["selection_amount_kg"], 0.0)

# ìˆ˜í‰ì„ ë“¤ (ê¸°ê°„ ì „ì²´ ê³ ì •ê°’: b/expected/x)
b_rate   = float(srow.get("b_rate", 0.0)) if "b_rate" in srow else 0.0
exp_rate = float(srow.get("expected_recent_rate", b_rate)) if "expected_recent_rate" in srow else b_rate
x_rate   = float(srow.get("x_rate", 0.0)) if "x_rate" in srow else 0.0

lines_df = pd.DataFrame({
    "dt":   list(daily["dt"]) * 3,
    "value": [b_rate] * len(daily) + [exp_rate] * len(daily) + [x_rate] * len(daily),
    "type":  (["ê¸°ì¤€ì„  b_rate"] * len(daily)) + (["ìµœê·¼ ê¸°ëŒ€ expected_rate"] * len(daily)) + (["ìµœê·¼ ì‹¤ì¸¡ x_rate"] * len(daily)),
})

# (1) ì‹œê°í™”: ì„ ë³„ æœ‰/ç„¡ë¥¼ ìƒ‰/ëª¨ì–‘ìœ¼ë¡œ êµ¬ë¶„
recent_start = TODAY - timedelta(days=RECENT_DAYS-1)
band = alt.Chart(pd.DataFrame({"start":[recent_start], "end":[TODAY]})).mark_rect(
    opacity=0.08, color="#E53935"
).encode(x="start:T", x2="end:T")

points_sel = alt.Chart(daily[daily["has_selection"]]).mark_circle(size=55, opacity=0.75).encode(
    x=alt.X("dt:T", title="ì¼ì"),
    y=alt.Y("daily_rate:Q", title="ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€ (count/kg)", axis=alt.Axis(format=".4f")),
    color=alt.value("#1E88E5"),
    shape=alt.value("circle"),
    tooltip=["dt:T","count:Q","selection_amount_kg:Q","daily_rate:Q"]
)

points_nosel = alt.Chart(daily[~daily["has_selection"]]).mark_square(size=45, opacity=0.45).encode(
    x=alt.X("dt:T"),
    y=alt.Y("daily_rate:Q"),
    color=alt.value("#9E9E9E"),
    shape=alt.value("square"),
    tooltip=["dt:T", alt.Tooltip("selection_amount_kg:Q", title="selection_kg")]
)

lines = alt.Chart(lines_df).mark_line(size=2).encode(
    x="dt:T",
    y=alt.Y("value:Q", title="ì¼ì¼ ì´ë¬¼ìˆ˜ì¤€ (count/kg)", axis=alt.Axis(format=".4f")),
    color=alt.Color("type:N", title=None)
)

st.altair_chart((band + points_nosel + points_sel + lines).properties(height=360), use_container_width=True)
st.caption("â€¢ ì›í˜•=ì„ ë³„ æœ‰, íšŒìƒ‰ ì‚¬ê°í˜•=ì„ ë³„ ç„¡  â€¢ ì„ : b_rate / expected_recent_rate / x_rate (ê¸°ê°„ ì „ì²´ ë™ì¼ ê°’)")

# -----------------------------
# (2) ì›ë£Œì—…ì²´ SPC ê´€ë¦¬ë„(u-chart) + (3) í†µê³„ í‰ê°€/ê°œì„  ì œì•ˆ
# -----------------------------
st.markdown("###### â–· ì—…ì²´ SPC ê´€ë¦¬ë„(u-chart) (ì„ ë³„ì¼ìˆ˜ â‰¥ 20ì¼ì¼ ë•Œ í‘œì‹œ)")

# âœ… ë³€ê²½ëœ ì§‘ê³„ ê¸°ì¤€:
#   ì„ íƒëœ supplier_code + material_code + contam_type ê¸°ì¤€ìœ¼ë¡œ
#   í˜„ì¬ í™”ë©´ í•„í„° ë‚´ì—ì„œ ì¼ë³„ ì´ count / ì´ kg ì§‘ê³„
sup_mask = (
    (fdf["dt"] >= base_start) & (fdf["dt"] <= TODAY) &
    (fdf["supplier_code"] == srow["supplier_code"]) &
    (fdf["material_code"] == srow["material_code"]) &
    (fdf["contam_type"]   == srow["contam_type"])
)
sup_ts = fdf.loc[sup_mask, ["dt","count","selection_amount_kg"]].copy()

# ì¼ë³„ í•©ê³„ (ëª¨ìˆ˜ 0ì¼ ì œì™¸)
sup_daily = (sup_ts.groupby("dt", as_index=False)
                .agg(count=("count","sum"), kg=("selection_amount_kg","sum"))
                .sort_values("dt"))
sup_daily = sup_daily[sup_daily["kg"] > 0]

if len(sup_daily) < 20:
    st.info(
        f"SPC í‘œì‹œ ë³´ë¥˜: ì„ íƒ ì¡°í•© "
        f"(supplier={srow['supplier_code']}, material={srow['material_code']}, contam={srow['contam_type']}) "
        f"ì„ ë³„ì¼ ìˆ˜ê°€ {len(sup_daily)}ì¼ì…ë‹ˆë‹¤. (â‰¥ 20ì¼ í•„ìš”)"
    )
else:
    # u-chart ê³„ì‚°
    ubar = sup_daily["count"].sum() / sup_daily["kg"].sum()
    sup_daily["u"] = sup_daily["count"] / sup_daily["kg"]
    sup_daily["ucl"] = ubar + 3.0 * np.sqrt(np.maximum(ubar, 0) / sup_daily["kg"])
    sup_daily["lcl"] = np.maximum(0.0, ubar - 3.0 * np.sqrt(np.maximum(ubar, 0) / sup_daily["kg"]))
    sup_daily["z"] = np.where(ubar > 0, (sup_daily["u"] - ubar) / np.sqrt(ubar / sup_daily["kg"]), 0.0)

    # SPC ì°¨íŠ¸
    u_line = alt.Chart(sup_daily).mark_line(color="#3949AB").encode(
        x="dt:T", y=alt.Y("u:Q", title="ê²°ì ë¥  u (count/kg)", axis=alt.Axis(format=".4f"))
    )
    cl_rule = alt.Chart(sup_daily).mark_rule(color="#00897B", strokeDash=[6,4]).encode(
        x="dt:T", y="mean(u):Q"  # ì¤‘ì•™ì„ (â‰ˆ ubar)
    )
    ucl_line = alt.Chart(sup_daily).mark_line(color="#E53935", strokeDash=[4,3]).encode(
        x="dt:T", y="ucl:Q"
    )
    lcl_line = alt.Chart(sup_daily).mark_line(color="#E53935", strokeDash=[4,3]).encode(
        x="dt:T", y="lcl:Q"
    )
    pts_spc = alt.Chart(sup_daily).mark_circle(size=50).encode(
        x="dt:T", y="u:Q",
        color=alt.condition("datum.u > datum.ucl || datum.u < datum.lcl",
                            alt.value("#E53935"), alt.value("#43A047")),
        tooltip=["dt:T","count:Q","kg:Q","u:Q","ucl:Q","lcl:Q","z:Q"]
    )

    st.altair_chart((ucl_line + lcl_line + cl_rule + u_line + pts_spc).properties(height=300),
                    use_container_width=True)

    # (3) í†µê³„ì /ê³¼í•™ì  í‰ê°€ & ê°œì„  ì œì•ˆ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    n = len(sup_daily)
    out_hi = int((sup_daily["u"] > sup_daily["ucl"]).sum())
    out_lo = int((sup_daily["u"] < sup_daily["lcl"]).sum())
    out_rate = (out_hi + out_lo) / n
    z_abs_max = float(np.abs(sup_daily["z"]).max())

    # ê³¼ì‚°í¬ ê°„ë‹¨ ì²´í¬
    var_obs = float(np.var(sup_daily["count"] - sup_daily["kg"] * ubar, ddof=1))
    var_exp = float(np.mean(sup_daily["kg"] * ubar))
    overdisp = var_obs > 1.5 * var_exp

    verdict = []
    if out_rate >= 0.05 or z_abs_max >= 3.5:
        verdict.append("**ê´€ë¦¬ë¶ˆëŸ‰(ê²½ë³´ ìˆ˜ì¤€)**: ê´€ë¦¬í•œê³„ ìœ„ë°˜ìœ¨ì´ ë†’ê±°ë‚˜ ê·¹ë‹¨ì¹˜ê°€ í¼.")
    elif out_rate >= 0.02 or z_abs_max >= 3.0:
        verdict.append("**ì£¼ì˜ í•„ìš”**: ë³€ë™ì„±ì´ ì»¤ì§€ê³  ìˆìŒ.")
    else:
        verdict.append("**ê´€ë¦¬ì–‘í˜¸**: í†µê³„ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìˆ˜ì¤€.")
    if overdisp:
        verdict.append("**ê³¼ì‚°í¬ ì˜ì‹¬**: ë‹¨ìˆœ í¬ì•„ì†¡ ê°€ì •ë³´ë‹¤ ì‚°í¬ê°€ í½ë‹ˆë‹¤.")

    actions = [
        "- **ìì„Â·ì²´Â·ê¸ˆì†ê²€ì¶œê¸°** ì ê²€ ì£¼ê¸° ë‹¨ì¶• ë° ê°ë„ ì¬ê²€ì¦",
        "- **LOTë³„ ì´ë¬¼ ì´ë ¥** ì‚¬ì „ì‹¬ì‚¬(ì…ê³ ê²€ì‚¬ ê°•í™”), ê³ ìœ„í—˜ LOT ì„ ë³„ ìš°ì„ ",
        "- **ì„¤ë¹„ ì²­ê²°/ì„¸ì²™ SOP** ê°•í™”, êµëŒ€/ì‘ì—…ì í¸ì°¨ ëª¨ë‹ˆí„°ë§",
        "- **ì„ ë³„ëŸ‰/ì†ë„ ìµœì í™”**ë¡œ ê³¼ë¶€í•˜ êµ¬ê°„ ì œê±°",
    ]
    st.markdown("**í†µê³„ í‰ê°€:** " + " ".join(verdict))
    st.markdown("**ê°œì„  ì œì•ˆ:**")
    st.markdown("\n".join([f"  {a}" for a in actions]))

# ----- ì—¬ê¸°ê¹Œì§€ êµì²´ -----

# =============================
# 3) ìµœê·¼ 2ì¼ ì¹˜ëª…ì  ì´ë¬¼ ì¶”ì  & êµì°¨ê³µì¥ ì‚¬ìš© ì´ë ¥ (ë³´ì™„íŒ)
# =============================
st.markdown("#### ğŸ” ìµœê·¼ 2ì¼ ì¹˜ëª…ì  ì´ë¬¼ ì›ë£Œ ì¶”ì  & êµì°¨ê³µì¥ ì‚¬ìš© ì´ë ¥")

def _crit_key(x):
    """ê¸ˆì†/ìœ ë¦¬ ê³„ì—´ì„ í•œ/ì˜/í‘œê¸°ë³€í˜• í¬í•¨í•´ ê³µí†µ í‚¤ë¡œ ì •ê·œí™”."""
    s = str(x).strip().lower()
    if any(k in s for k in ["ê¸ˆì†", "metal"]):
        return "metal"
    if any(k in s for k in ["ìœ ë¦¬", "glass"]):
        return "glass"
    return None

# (A) ìµœê·¼ 2ì¼ (TODAY í¬í•¨)
last2_start = TODAY - timedelta(days=1)
mask_last2_crit = (
    (fdf["dt"] >= last2_start) & (fdf["dt"] <= TODAY) &
    (fdf["count"] > 0) &
    fdf["contam_type"].apply(lambda v: _crit_key(v) is not None)
)

cols_needed = [
    "dt","plant","line","lot_no","contam_type","count","selection_amount_kg",
    "material_code","material_name","supplier_code","supplier_name","material_type"
]
for c in cols_needed:
    if c not in fdf.columns:
        fdf[c] = "" if c not in ["count","selection_amount_kg"] else 0

crit_last2_raw = fdf.loc[mask_last2_crit, cols_needed].copy()
crit_last2_raw["crit_key"] = crit_last2_raw["contam_type"].map(_crit_key)

if crit_last2_raw.empty:
    st.info("ìµœê·¼ 2ì¼ ë‚´ ì¹˜ëª…ì  ì´ë¬¼(ê¸ˆì†/ìœ ë¦¬) ë°œìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # â‘  ìµœê·¼ 2ì¼ ì¹˜ëª…ì  ì´ë¬¼ ë°œìƒ ëª©ë¡ (ìš”êµ¬ ì»¬ëŸ¼ìœ¼ë¡œ í‘œì‹œ, lot_no ê·¸ëŒ€ë¡œ)
    grp_cols = ["plant","line","dt","lot_no","contam_type","material_code","supplier_code"]
    crit_last2 = (
        crit_last2_raw
        .groupby(grp_cols, as_index=False)
        .agg(
            ë°œìƒê±´ìˆ˜=("count","sum"),
            selection_amount_kg=("selection_amount_kg","sum"),
            material_name=("material_name","first"),
            supplier_name=("supplier_name","first"),
            material_type=("material_type","first"),
            crit_key=("crit_key","first")
        )
        .sort_values(["dt","plant","line"], ascending=[False,True,True])
    )

    st.markdown("##### â‘  ìµœê·¼ 2ì¼ ì¹˜ëª…ì  ì´ë¬¼ ë°œìƒ ëª©ë¡")
    st.dataframe(
        crit_last2[[
            "plant","line","dt","lot_no","contam_type","ë°œìƒê±´ìˆ˜","selection_amount_kg",
            "material_code","supplier_code","material_name","supplier_name","material_type"
        ]],
        use_container_width=True
    )

    # ì„ íƒ(â‘  â†’ â‘¡)
    def _lab(r):
        return f"{r['dt']} | {r['plant']} | {r['line']} | lot_no={r['lot_no']} | {r['contam_type']} | {r['material_code']} | {r['supplier_code']}"
    crit_last2["label"] = crit_last2.apply(_lab, axis=1)

    sel_label = st.selectbox("ì›ë£Œ ì„ íƒ (â†’ ë™ì¼ ì›ë£Œì˜ íƒ€ ê³µì¥ ì‚¬ìš© ì´ë ¥ ì¡°íšŒ)",
                             options=crit_last2["label"].tolist())
    sel = crit_last2[crit_last2["label"]==sel_label].iloc[0]

    sel_mat = sel["material_code"]
    sel_sup = sel["supplier_code"]
    sel_lot = str(sel["lot_no"]) if pd.notna(sel["lot_no"]) else ""
    sel_plant = sel["plant"]
    sel_line  = sel["line"]
    sel_dt    = sel["dt"]
    sel_contam= sel["contam_type"]
    sel_crit  = sel["crit_key"]  # "metal" ë˜ëŠ” "glass"
    sel_cnt   = int(sel["ë°œìƒê±´ìˆ˜"])
    sel_kg    = float(sel["selection_amount_kg"])
    sel_mname = sel["material_name"]
    sel_sname = sel["supplier_name"]

    # (B) ë™ì¼ ì›ë£Œ(ì½”ë“œ+ì—…ì²´)ë¡œ ìµœê·¼ 180ì¼ 'ë‹¤ë¥¸ plant' ì‚¬ìš© ì´ë ¥ (+ ë™ì¼ ì´ë¬¼ë§Œì˜ ë°œìƒê±´ìˆ˜)
    search_start = baseline_start
    base180 = fdf[
        (fdf["dt"] >= search_start) & (fdf["dt"] <= TODAY) &
        (fdf["material_code"] == sel_mat) &
        (fdf["supplier_code"] == sel_sup) &
        (fdf["plant"] != sel_plant)
    ].copy()
    base180["crit_key"] = base180["contam_type"].map(_crit_key)

    if base180.empty:
        st.info("ìµœê·¼ 180ì¼ ë™ì•ˆ ë™ì¼ ì›ë£Œ(ì½”ë“œ+ì—…ì²´)ì˜ íƒ€ ê³µì¥ ì‚¬ìš© ì‹¤ì ì´ ì—†ìŠµë‹ˆë‹¤.")
        usage = pd.DataFrame()
    else:
        # ë™ì¼ LOT ì—¬ë¶€
        base180["same_lot"] = False
        if sel_lot.strip():
            base180["same_lot"] = base180["lot_no"].astype(str).eq(sel_lot)

        # ì‚¬ìš©ëŸ‰ ì§‘ê³„
        usage_base = (
            base180.groupby(["plant","line","dt","lot_no"], as_index=False)
                   .agg(usage_kg=("selection_amount_kg","sum"))
        )

        # ë™ì¼ ì´ë¬¼ë§Œì˜ ë°œìƒê±´ìˆ˜ ì§‘ê³„ (â‘ ì—ì„œì˜ ì´ë¬¼ ê³„ì—´(sel_crit)ê³¼ ì¼ì¹˜í•˜ëŠ” ê±´ë§Œ í•©ì‚°)
        samecrit = base180[base180["crit_key"] == sel_crit]
        samecrit_cnt = (
            samecrit.groupby(["plant","line","dt","lot_no"], as_index=False)
                    .agg(same_critical_count=("count","sum"))
        )

        # ë™ì¼ LOT ì‚¬ìš© ê°•ì¡° í”Œë˜ê·¸ (ë‚ ì§œ ë‹¨ìœ„ë¡œ OR)
        same_lot_flag = (
            base180.groupby(["plant","line","dt","lot_no"], as_index=False)
                   .agg(same_lot=("same_lot","max"))
        )

        # ê²°í•©
        usage = (usage_base
                 .merge(samecrit_cnt, on=["plant","line","dt","lot_no"], how="left")
                 .merge(same_lot_flag, on=["plant","line","dt","lot_no"], how="left")
                 .fillna({"same_critical_count": 0, "same_lot": False})
                 .sort_values(["same_lot","dt"], ascending=[False, False])
                 )

        st.markdown("##### â‘¡ ë™ì¼ ì›ë£Œ(ì½”ë“œ+ì—…ì²´)ì˜ íƒ€ ê³µì¥ ì‚¬ìš© ì‹¤ì  (ìµœê·¼ 180ì¼)")
        # lot_no ì´ë¦„ ê·¸ëŒ€ë¡œ ìœ ì§€
        show_usage = usage.rename(columns={
            "plant":"ì‚¬ì—…ì¥","line":"ì„ ë³„ë¼ì¸","dt":"ì„ ë³„ì¼ì","same_lot":"same_lot"
        })[["ì‚¬ì—…ì¥","ì„ ë³„ë¼ì¸","ì„ ë³„ì¼ì","lot_no","usage_kg","same_critical_count","same_lot"]]

        # ê°•ì¡° ì»¬ëŸ¼
        show_usage["âš ï¸"] = np.where(show_usage["same_lot"], "âš ï¸ ë™ì¼ LOT ì‚¬ìš©", "")
        st.dataframe(
            show_usage[["âš ï¸","ì‚¬ì—…ì¥","ì„ ë³„ë¼ì¸","ì„ ë³„ì¼ì","lot_no","usage_kg","same_critical_count"]],
            use_container_width=True
        )
        st.download_button(
            "â‘¡ ì‚¬ìš© ì‹¤ì  CSV ë‹¤ìš´ë¡œë“œ",
            data=show_usage.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"cross_plant_usage_{sel_mat}_{sel_sup}.csv"
        )

    # (C) ìë™ ê²½ë³´ ë©”ì‹œì§€ (íƒ€ ê³µì¥ + ë²¤ë”)
    st.markdown("##### â‘¢ ìë™ ê²½ë³´ ë©”ì‹œì§€")

    # â‘¢-1 íƒ€ ê³µì¥ìš©: â‘¡ì˜ ìš”ì•½(ë™ì¼ LOT / same_critical_count í¬í•¨)ë„ í•¨ê»˜ ì‚½ì…
    lines_to = []
    lines_to.append("[ìë™ê²½ë³´] ì¹˜ëª…ì  ì´ë¬¼ ë°œìƒ(ê¸ˆì†/ìœ ë¦¬) â€“ ë™ì¼ ì›ë£Œ ì‚¬ìš© ì£¼ì˜")
    lines_to.append(f"- ì›ë£Œ: {sel_mname} (ì½”ë“œ {sel_mat}), ì—…ì²´: {sel_sname} (ì½”ë“œ {sel_sup}), LOT: {sel_lot or '(ë¯¸ê¸°ì¬)'}")
    lines_to.append(f"- ë°œìƒ: {sel_dt} @ {sel_plant}/{sel_line}, ì´ë¬¼={sel_contam}, ê±´ìˆ˜={sel_cnt}, ë‹¹ì¼ ì„ ë³„ëŸ‰={int(sel_kg)}kg")
    lines_to.append("- íƒ€ ê³µì¥ ì‚¬ìš©/ë°œìƒ ìš”ì•½(ìµœê·¼ 180ì¼):")
    if not base180.empty and not usage.empty:
        # ìµœì‹ ì¼ ìš°ì„  ìƒìœ„ Nì¤„ ìš”ì•½
        for _, r in usage.sort_values("dt", ascending=False).head(20).iterrows():
            lot_tag = " âš ï¸ë™ì¼LOT" if r.get("same_lot", False) else ""
            lines_to.append(
                f"  Â· {r['plant']} / {r['line']} @ {r['dt']} | lot_no={r['lot_no']} | ì‚¬ìš©ëŸ‰={int(r['usage_kg'])}kg | "
                f"ë™ì¼ì´ë¬¼ë°œìƒê±´ìˆ˜={int(r['same_critical_count'])}{lot_tag}"
            )
    else:
        lines_to.append("  Â· ë™ì¼ ì›ë£Œì˜ íƒ€ ê³µì¥ ì‚¬ìš© ì´ë ¥ì´ ì—†ê±°ë‚˜ ì§‘ê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    lines_to.append("- ì¡°ì¹˜ ìš”ì²­:")
    lines_to.append("  1) í•´ë‹¹ ì›ë£Œ(ê°€ëŠ¥ ì‹œ ë™ì¼ LOT) **ì¦‰ì‹œ ì‚¬ìš© ì¤‘ì§€(Hold)**")
    lines_to.append("  2) ì°½ê³ /ë¼ì¸ **ì¬ê³  ë° ì‚¬ìš© ì´ë ¥ í™•ì¸**, ë™ì¼ LOT ì‚¬ìš© ì—¬ë¶€ ì ê²€")
    lines_to.append("  3) ê¸ˆì†ê²€ì¶œ/ì´ë¬¼ì„ ë³„ **ë³´ê°• ê²€ì‚¬** ì‹œí–‰")
    lines_to.append("  4) ê²°ê³¼ íšŒì‹  ë° ì¡°ì¹˜ ì™„ë£Œ ë³´ê³ ")

    msg_to_plants = "\n".join(lines_to)
    st.text_area("íƒ€ ê³µì¥ ê²½ë³´ë¬¸", value=msg_to_plants, height=280)
    st.download_button("íƒ€ ê³µì¥ ê²½ë³´ë¬¸ .txt", data=msg_to_plants.encode("utf-8-sig"),
                       file_name=f"alert_to_plants_{sel_mat}_{sel_sup}_{sel_lot or 'nolot'}.txt")

    # â‘¢-2 ë²¤ë”/ì œì¡°ì—…ì²´ìš©
    lines_v = []
    lines_v.append("[ìš”ì²­] ì¹˜ëª…ì  ì´ë¬¼(ê¸ˆì†/ìœ ë¦¬) ë°œìƒ ê´€ë ¨ ì›ì¸ì¡°ì‚¬ ë° CAPA ì œì¶œ")
    lines_v.append(f"- ì›ë£Œëª…/ì½”ë“œ: {sel_mname} / {sel_mat}")
    lines_v.append(f"- ì—…ì²´ëª…/ì½”ë“œ: {sel_sname} / {sel_sup}")
    lines_v.append(f"- LOT: {sel_lot or '(ë¯¸ê¸°ì¬)'}")
    lines_v.append(f"- ë°œìƒì •ë³´: {sel_dt} @ {sel_plant}/{sel_line}, ì´ë¬¼={sel_contam}, ê±´ìˆ˜={sel_cnt}, ë‹¹ì¼ ì„ ë³„ëŸ‰={int(sel_kg)}kg")
    lines_v.append("- ìš”ì²­ì‚¬í•­:")
    lines_v.append("  1) í•´ë‹¹ LOT í¬í•¨ ì¶œí•˜ë¶„ **ì „ëŸ‰ ì¶œí•˜ì •ì§€(Hold)** ë° ì¬ê³  ê²©ë¦¬")
    lines_v.append("  2) **ì›ì¸ ë¶„ì„**(ê³µì •/ì›ìì¬/ì„¤ë¹„/ì¸ë ¥/ì„¸ì²™/ìì„Â·ì²´ ë¶„ë¦¬ì¥ì¹˜ ì ê²€)")
    lines_v.append("  3) **ê·¼ë³¸ëŒ€ì±…(CAPA)** ìˆ˜ë¦½ ë° ì˜ˆë°©ì¡°ì¹˜ ê³„íš(ê¸°í•œ í¬í•¨)")
    lines_v.append("  4) **ë™ì¼ LOT/ë™ì¼ ì„¤ë¹„** ìƒì‚°ë¶„ì˜ ì¶”ì ìë£Œ ë° ê²€ì‚¬ì„±ì ì„œ(COA) ì œì¶œ")
    lines_v.append("  5) íšŒì‹  ê¸°í•œ: ì˜ì—…ì¼ ê¸°ì¤€ 3ì¼ ë‚´ 1ì°¨ íšŒì‹ , 10ì¼ ë‚´ ìµœì¢… ë³´ê³ ")
    msg_to_vendor = "\n".join(lines_v)

    st.text_area("ë²¤ë”/ì œì¡°ì—…ì²´ í†µì§€ë¬¸", value=msg_to_vendor, height=260)
    st.download_button("ë²¤ë” í†µì§€ë¬¸ .txt", data=msg_to_vendor.encode("utf-8-sig"),
                       file_name=f"notice_to_vendor_{sel_mat}_{sel_sup}_{sel_lot or 'nolot'}.txt")


# -----------------------------
# â‘¢ ì•¡ì…˜ í…œí”Œë¦¿ (í™”ë©´ ì¶œë ¥ + ë³µì‚¬ + txt)
# -----------------------------
with tab3:
    st.subheader("ì•¡ì…˜ í…œí”Œë¦¿ ìƒì„±")

    surge_all = st.session_state.get("alerts_surge", pd.DataFrame())
    novel_view = st.session_state.get("alerts_novel", pd.DataFrame())

    if surge_all is None or surge_all.empty:
        st.info("ê²½ë³´ ë³´ë“œì—ì„œ ê²°ê³¼ê°€ ìƒì„±ëœ í›„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        # ì •ìƒ ì œì™¸ + |z| ë‚´ë¦¼ì°¨ìˆœ
        non_normal = surge_all[surge_all["flag"]!="ì •ìƒ"].copy()
        if non_normal.empty:
            st.info("ìƒìŠ¹/í•˜ë½ ê²½ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            non_normal["abs_z"] = non_normal["z"].abs()
            top_n = st.slider("ì•Œë¦¼ ìƒìœ„ N(|z| ê¸°ì¤€)", min_value=5, max_value=100, value=20, step=5)
            top_df = non_normal.sort_values("abs_z", ascending=False).head(top_n)

            today_str = datetime.now().strftime("%Y-%m-%d")
            intro = f"[ìë™ìƒì„±] ì´ë¬¼ìˆ˜ì¤€ ê¸‰ì¦/í•˜ë½Â·ì‹ ê·œ ìœ í˜• ëª¨ë‹ˆí„°ë§ ì•Œë¦¼ â€“ {today_str}\n"

            lines_out = []
            for _, r in top_df.iterrows():
                key = f"{r.get('supplier_code','')}-{r.get('material_code','')}-{r.get('contam_type','')}"
                lines_out.append(
                    f"â€¢ {key}: ìµœê·¼ rate={r.get('x_rate',0):.4f}, ê¸°ì¤€ì„  rate={r.get('b_rate',0):.4f}, z={r.get('z',0):.2f}, íŒì •={r.get('flag','')}"
                )
            summary = "\n".join(lines_out[:200])

            novel_lines = []
            if novel_view is not None and not novel_view.empty:
                for _, r in novel_view.head(20).iterrows():
                    key = f"{r.get('supplier_code','')}-{r.get('material_code','')}"
                    novel_lines.append(f"â€¢ [ì‹ ê·œ] {key}ì—ì„œ '{r.get('contam_type','')}' ìµœì´ˆ ë°œìƒ @ {r.get('dt')}")
            novel_text = "\n".join(novel_lines)

            guidance = (
                "\n[ê¶Œê³  ì•¡ì…˜]\n"
                "- ê³µì • ì„ ë³„ê°•ë„ ìƒí–¥ ë° í•´ë‹¹ LOT ì¶”ê°€ê²€ì‚¬\n"
                "- ê³µê¸‰ì‚¬ ì›ì¸ì ê²€ ìš”ì²­(ì‚¬ì§„/ì¦ë¹™ ì²¨ë¶€)\n"
                "- (ì„ê³„ ì´ˆê³¼ ì‹œ) ì›ë£Œ LOT Hold ë° ê´€ë ¨ ì œí’ˆ LOT ì¶œê³ ì¤‘ì§€ ê²€í† \n"
                "- CAPA ë“±ë¡ ë° ì¬ë°œë°©ì§€ ì¶”ì "
            )

            email_text = intro + "\n[ê¸‰ì¦Â·í•˜ë½ ìƒìœ„ ìš”ì•½]\n" + summary + ("\n\n[ì‹ ê·œ ì´ë¬¼ ê°ì§€]\n" + novel_text if novel_text else "") + guidance

            st.markdown("#### ğŸ“£ ë°œì†¡/ê³µìœ ìš© ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°")
            st.text_area("ë³¸ë¬¸", value=email_text, height=300)

            # ë³µì‚¬ ë²„íŠ¼
            components.html(
                f"""
                <button onclick="navigator.clipboard.writeText({email_text!r});
                                 const s=this; s.innerText='ë³µì‚¬ë¨!'; setTimeout(()=>s.innerText='í´ë¦½ë³´ë“œë¡œ ë³µì‚¬',1200);"
                        style="padding:8px 14px; border-radius:8px; border:1px solid #ddd; cursor:pointer;">
                    í´ë¦½ë³´ë“œë¡œ ë³µì‚¬
                </button>
                """,
                height=60
            )
            st.download_button("ë³¸ë¬¸ .txt ë‹¤ìš´ë¡œë“œ", data=email_text.encode("utf-8-sig"), file_name="alert_message.txt")

# -----------------------------
# â‘£ ë‚´ë³´ë‚´ê¸° (CSV/XLSX)
# -----------------------------
with tab4:
    st.subheader("ê²°ê³¼ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°")

    f = st.session_state.get("filtered_df", pd.DataFrame())
    pv = st.session_state.get("pivot_df", None)
    nov = st.session_state.get("alerts_novel", pd.DataFrame())
    surge = st.session_state.get("alerts_surge", pd.DataFrame())

    if not f.empty:
        st.download_button("í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=f.to_csv(index=False).encode("utf-8-sig"), file_name="filtered_incidents.csv")
    else:
        st.info("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (íƒ­â‘ ì—ì„œ ì¡°ê±´ì„ ì¡°ì •í•˜ì„¸ìš”)")

    # XLSX ì—”ì§„ í´ë°± (XlsxWriter -> openpyxl)
    try:
        import xlsxwriter  # noqa
        engine = "xlsxwriter"
    except Exception:
        engine = "openpyxl"

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine=engine) as writer:
        if not f.empty:
            f.to_excel(writer, sheet_name="FilteredData", index=False)
            try:
                writer.sheets["FilteredData"].freeze_panes(1,0)
            except Exception:
                pass
        if pv is not None:
            pv_out = pv.copy()
            if isinstance(pv_out, pd.Series):
                pv_out = pv_out.to_frame("value")
            if isinstance(pv_out.index, pd.MultiIndex):
                pv_out.index = [' | '.join(map(str, t)) for t in pv_out.index]
            if isinstance(pv_out.columns, pd.MultiIndex):
                pv_out.columns = [' | '.join(map(str, t)) for t in pv_out.columns]
            pv_out.to_excel(writer, sheet_name="Pivot", merge_cells=False)
            try:
                writer.sheets["Pivot"].freeze_panes(1,1)
            except Exception:
                pass
        if nov is not None and not nov.empty:
            nov.to_excel(writer, sheet_name="NovelAlerts", index=False)
            try:
                writer.sheets["NovelAlerts"].freeze_panes(1,0)
            except Exception:
                pass
        if surge is not None and not surge.empty:
            surge.to_excel(writer, sheet_name="SurgeAlerts", index=False)
            try:
                writer.sheets["SurgeAlerts"].freeze_panes(1,0)
            except Exception:
                pass

    st.download_button("ì—‘ì…€ ë³´ê³ ì„œ(XLSX) ë‹¤ìš´ë¡œë“œ", data=output.getvalue(), file_name="FOCast_report.xlsx")

st.caption("â€» ê³ ë„í™”: rate ì„ê³„ì¹˜ ì •ì±…/ê°€ì¤‘, LOTâ†”ì œí’ˆ íŠ¸ë ˆì´ìŠ¤, ìë™ ë©”ì¼/Teams ì „ì†¡(Graph API) ë“± í™•ì¥ ê°€ëŠ¥.")
